<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | Koustuv Sinha</title><link>https://koustuvsinha.com/project/</link><atom:link href="https://koustuvsinha.com/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Jul 2021 00:00:00 +0000</lastBuildDate><image><url>https://koustuvsinha.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://koustuvsinha.com/project/</link></image><item><title>UnNatural Language Inference</title><link>https://koustuvsinha.com/project/unli/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://koustuvsinha.com/project/unli/</guid><description>&lt;p>&lt;strong>Abstract&lt;/strong>&lt;/p>
&lt;p>Recent investigations into the inner-workings of state-of-the-art
large-scale pre-trained Transformer-based Natural Language Understanding
(NLU) models indicate that they appear to understand human-like syntax,
at least to some extent. We provide novel evidence that complicates this
claim: we find that state-of-the-art Natural Language Inference (NLI)
models assign the same labels to permuted examples as they do to the
original, i.e. they are invariant to random word-order permutations.
This behavior notably differs from that of humans; we struggle to
understand the meaning of ungrammatical sentences. To measure the
severity of this issue, we propose a suite of metrics and investigate
which properties of particular permutations lead models to be word order
invariant. For example, in MNLI dataset we find almost all (98.7%)
examples contain at least one permutation which elicits the gold label.
Models are even able to assign gold labels to permutations that they
originally failed to predict correctly. We provide a comprehensive
empirical evaluation of this phenomenon, and further show that this
issue exists in pre-Transformer RNN / ConvNet based encoders, as well as
across multiple languages (English and Chinese). Our code and data are
available at &lt;a href="https://github.com/facebookresearch/unlu" target="_blank" rel="noopener">https://github.com/facebookresearch/unlu&lt;/a>.&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://koustuvsinha.com/ox-hugo/anim_30.gif" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h2 id="news">Latest News&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>July 3, 2021&lt;/strong> : We are honored to be awarded &lt;a href="https://2021.aclweb.org/program/accept/" target="_blank" rel="noopener">Outstanding Paper Award&lt;/a> in ACL-IJCNLP 2021!&lt;/li>
&lt;/ul></description></item><item><title>GraphLog</title><link>https://koustuvsinha.com/project/graphlog/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://koustuvsinha.com/project/graphlog/</guid><description>&lt;p>&lt;em>Koustuv Sinha, Shagun Sodhani, Joelle Pineau, William L. Hamilton&lt;/em>&lt;/p>
&lt;p>&lt;strong>Abstract&lt;/strong>&lt;/p>
&lt;p>Recent research has highlighted the role of relational inductive biases
in building learning agents that can generalize and reason in a
compositional manner. However, while relational learning algorithms such as graph neural networks (GNNs) show promise, we do not understand how effectively these approaches can adapt to new tasks. In this work, we
study the task of &lt;em>logical generalization&lt;/em> using GNNs by designing a
benchmark suite grounded in first-order logic. Our benchmark suite,
&lt;strong>&lt;code>GraphLog&lt;/code>&lt;/strong>, requires that learning algorithms perform rule induction
in different synthetic logics, represented as knowledge graphs.
&lt;strong>&lt;code>GraphLog&lt;/code>&lt;/strong> consists of relation prediction tasks on 57 distinct
logical domains. We use &lt;strong>&lt;code>GraphLog&lt;/code>&lt;/strong> to evaluate GNNs in three different
setups: single-task supervised learning, multi-task pretraining, and
continual learning. Unlike previous benchmarks, our approach allows us
to precisely control the logical relationship between the different
tasks. We find that the ability for models to generalize and adapt is
strongly determined by the diversity of the logical rules they encounter
during training, and our results highlight new challenges for the design
of GNN models.&lt;/p>
&lt;h2 id="news">Latest News&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>May 24, 2020&lt;/strong> : Code for experiments in the paper released in &lt;a href="https://github.com/facebookresearch/GraphLog/tree/master/experiments" target="_blank" rel="noopener">GraphLog repository&lt;/a>&lt;/li>
&lt;li>&lt;strong>April 25, 2020&lt;/strong> : Added simple &lt;a href="https://github.com/facebookresearch/GraphLog/tree/master/examples" target="_blank" rel="noopener">supervised experiments&lt;/a> using GraphLog in &lt;a href="https://pytorch-lightning.readthedocs.io/en/latest/" target="_blank" rel="noopener">Pytorch Lightning&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>CLUTRR</title><link>https://koustuvsinha.com/project/clutrr/</link><pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate><guid>https://koustuvsinha.com/project/clutrr/</guid><description>&lt;p>A Diagnostic Benchmark for Inductive Reasoning from Text.&lt;/p>
&lt;p>&lt;em>Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L. Hamilton&lt;/em>&lt;/p>
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>The recent success of natural language understanding (NLU) systems has been troubled by results highlighting the failure of these models to generalize in a systematic and robust way. In this work, we introduce a diagnostic benchmark suite, named CLUTRR, to clarify some key issues related to the robustness and systematicity of NLU systems. Motivated by classic work on inductive logic programming, CLUTRR requires that an NLU system infer kinship relations between characters in short stories. Successful performance on this task requires both extracting relationships between entities, as well as inferring the logical rules governing these relationships. CLUTRR allows us to precisely measure a model’s ability for systematic generalization by evaluating on held-out combinations of logical rules, and it allows us to evaluate a model’s robustness by adding curated noise facts. Our empirical results highlight a substantial performance gap between state-of-the-art NLU models (e.g., BERT and MAC) and a graph neural network model that works directly with symbolic inputs—with the graph-based model exhibiting both stronger generalization and greater robustness.&lt;/p></description></item><item><title>Turtle Learning Environment (TLE)</title><link>https://koustuvsinha.com/project/tle/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://koustuvsinha.com/project/tle/</guid><description>&lt;p>&lt;em>Minimalist connect-the-dots environment for RL agents!&lt;/em>&lt;/p>
&lt;p>Turtle Learning Environment (TLE) is a minimalistic connect-the-dots environment made as part of COMP 767 RL Final project in McGill University (Winter 2018). The objective of the agent in a 28x28 grid world is to connect the dots provided to form the image, where the environment provides negative reward for each cell drawn and positive reward for each connected components.&lt;/p></description></item><item><title>RLLChatBot</title><link>https://koustuvsinha.com/project/rllchatbot/</link><pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate><guid>https://koustuvsinha.com/project/rllchatbot/</guid><description>&lt;p>&lt;em>Koustuv Sinha, &lt;a href="http://cs.mcgill.ca/~nangel3" target="_blank" rel="noopener">Nicolas Angelard-Gontier&lt;/a>, &lt;a href="http://www.peterhenderson.co/" target="_blank" rel="noopener">Peter Henderson&lt;/a>, &lt;a href="http://cs.mcgill.ca/~pparth2/" target="_blank" rel="noopener">Prasanna Parthasarathy&lt;/a>, Mike Noseworthy &amp;amp; &lt;a href="http://cs.mcgill.ca/~jpineau/" target="_blank" rel="noopener">Joelle Pineau&lt;/a>&lt;/em>&lt;/p>
&lt;p>As a part of a broader &lt;a href="http://convai.io/" target="_blank" rel="noopener">ConvAI&lt;/a> challenge, we, the
Dialog Group of McGill University under the supervision of
&lt;a href="http://cs.mcgill.ca/~jpineau/" target="_blank" rel="noopener">Dr Joelle Pineau&lt;/a>, have trained a
chatbot which can converse fluently with human judges with respect to a given article. The articles are chosen from a broad corpus of
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener">SQUAD dataset&lt;/a>, where topically they vary from politics to sports to general news. The challenge is to have a fluent conversation with the bot, centering around the topic of the article. Current system uses an ensemble of Generative, Retrieval, and rule based models, and a decision agent learned over actual human-bot responses to select the best candidate response at a given time. We ranked third in the human evaluation round and ranked fourth in the final round held alongside NIPS 2017. Our proposal was also awarded
&lt;a href="https://research.fb.com/announcing-the-winners-of-the-facebook-parlai-research-awards/" target="_blank" rel="noopener">ParlAI research grant&lt;/a> from Facebook.&lt;/p></description></item><item><title>NetworkJS</title><link>https://koustuvsinha.com/project/networkjs/</link><pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate><guid>https://koustuvsinha.com/project/networkjs/</guid><description>&lt;p>Implemented modules:&lt;/p>
&lt;ul>
&lt;li>Degree Centrality&lt;/li>
&lt;li>Betweenness Centrality&lt;/li>
&lt;li>Eigenvalue Centrality&lt;/li>
&lt;/ul>
&lt;p>Built as a project for Comp 767, Fall 2016, McGill University&lt;/p></description></item></channel></rss>