@article{sinha2018hier,
 abstract = {Deep neural networks have been displaying superior
performance over traditional supervised classifiers in text
classification. They learn to extract useful features
automatically when sufficient amount of data is presented.
However, along with the growth in the number of documents
comes the increase in the number of categories, which often
results in poor performance of the multiclass classifiers. In
this work, we use external knowledge in the form of topic
category taxonomies to aide the classification by introducing
a deep hierarchical neural attention-based classifier. Our
model performs better than or comparable to state-of-the-art
hierarchical models at significantly lower computational cost
while maintaining high interpretability.},
 author = {Sinha, Koustuv and Dong, Yue and Chi-kit Cheung,
Jackie and Ruths, Derek},
 epdf = {http://www.aclweb.org/anthology/D18-1094},
 journal = {Empirical Methods of Natural Language Processing (EMNLP)},
 title = {A Hierarchical Neural Attention-based Text Classifier},
 year = {2018}
}

