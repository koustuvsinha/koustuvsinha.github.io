---
title: Home
---

{{< profile_image path="prof_pic.jpg" width=200 alt="Profile pic" >}}

# Koustuv Sinha

I'm a Research Scientist at [Meta AI](https://ai.meta.com/), in the Fundamental AI Research (FAIR) team. I received my PhD from [McGill University](http://mcgill.ca/) ([School of Computer Science](http://cs.mcgill.ca)) and [Mila (Quebec AI Institute)](https://mila.quebec), Montreal, Canada, where I was advised by Dr. [Joelle Pineau](https://www.cs.mcgill.ca/~jpineau/). I also received by MSc (Thesis) from McGill University, where I was advised by Dr. [Derek Ruths](https://derekruths.com/) and Dr. Joelle Pineau.

My current research interest involves investigating the role of multimodal language models at understanding and reasoning the world through rich visual representations, especially by leveraging language as a tool to decode and reason the underlying physical rules governing the world. My research also involves understanding the limits of [systematic](https://slideslive.com/38922304/from-system-1-deep-learning-to-system-2-deep-learning) language understanding - the ability of neural systems to understand language in a human-like way - by evaluating the extent of their capabilities in understanding semantics, syntax and generalizability.

I am also involved in improving and enabling reproducibile research in Machine Learning - I'm the lead organizer of the annual _Machine Learning Reproducibility Challenge_ ([V1](https://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html), [V2](https://www.cs.mcgill.ca/~jpineau/ICLR2019-ReproducibilityChallenge.html), [V3](https://reproducibility-challenge.github.io/neurips2019/), [V4](https://paperswithcode.com/rc2020), [V5](https://paperswithcode.com/rc2021), [V6](https://paperswithcode.com/rc2022), [v7](https://reproml.org/)), and I serve as an associate editor at [ReScience C](http://rescience.github.io/), a peer reviewed journal promoting reproducible research. My work has been covered by several news outlets in the past, including [Nature](https://www.nature.com/articles/d41586-019-03895-5), [VentureBeat](https://venturebeat.com/2021/01/15/facebook-claims-its-ai-can-anticipate-covid-19-outcomes-using-x-rays/), [InfoQ](https://www.infoq.com/news/2021/03/facebook-covid-prognosis/), [DailyMail](https://www.dailymail.co.uk/sciencetech/article-9153415/Facebook-claims-AI-predict-four-coronavirus-patients-condition-deteriorate.html) and [Hindustan Times](https://tech.hindustantimes.com/tech/news/facebook-wants-to-help-doctors-fight-covid-19-with-ai-and-xrays-71611044405211.html).

## Featured Publications

- [V-JEPA 2](https://arxiv.org/abs/2506.09985): Self-Supervised Video Models Enable Understanding, Prediction and Planning; _Mido Assran*, Adrien Bardes*, David Fan*, Quentin Garrido*, Russell Howes*, Mojtaba, Komeili*, Matthew Muckley*, Ammar Rizvi*, Claire Roberts\*, **Koustuv Sinha\***, Artem Zholus*, Sergio Arnaud*, Abha Gejji*, Ada Martin*, Francois Robert Hogan*, Daniel Dugas*, Piotr Bojanowski, Vasil Khalidov, Patrick Labatut, Francisco Massa, Marc Szafraniec, Kapil Krishnakumar, Yong Li, Xiaodong Ma, Sarath Chandar, Franziska Meier*, Yann LeCun*, Michael Rabbat*, Nicolas Ballas*_; [Huggingface](https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6) | [Code](https://github.com/facebookresearch/vjepa2) | [Blog](https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks/)
- [Scaling Language-Free Visual Representation Learning](https://arxiv.org/abs/2504.01017); _David Fan*, Shengbang Tong*, Jiachen Zhu, **Koustuv Sinha**, Zhuang Liu, Xinlei Chen, Michael Rabbat, Nicolas Ballas, Yann LeCun, Amir Bar, Saining Xie_; [Huggingface](https://huggingface.co/collections/facebook/web-ssl-68094132c15fbd7808d1e9bb) | [Code](https://github.com/facebookresearch/webssl) | [Project Page](https://davidfan.io/webssl/)
- [MetaMorph](https://arxiv.org/abs/2412.14164): Multimodal Understanding and Generation via Instruction Tuning; _Shengbang Tong*, David Fan*, Jiachen Zhu, Yunyang Xiong, Xinlei Chen, **Koustuv Sinha**, Michael Rabbat, Yann LeCun, Saining Xie, Zhuang Liu_
- [VEDIT](https://arxiv.org/abs/2410.03478): Latent Prediction Architecture For Procedural Video Representation Learning; _Han Lin, Tushar Nagarajan, Nicolas Ballas, Mido Assran, Mojtaba Komeili, Mohit Bansal, **Koustuv Sinha**_;
- [Chameleon](https://arxiv.org/abs/2405.09818): Mixed-Modal Early-Fusion Foundation Models; _Chameleon Team_; [Huggingface](https://huggingface.co/collections/facebook/chameleon-668da9663f80d483b4c61f58) | [Code](https://github.com/facebookresearch/chameleon) | [Blog](https://ai.meta.com/blog/meta-fair-research-new-releases/)

For a full and up to date list of my publications please visit my [Google Scholar](https://scholar.google.ca/citations?hl=en&user=9P9QcckAAAAJ) profile.

## News

{{< readfromfile "/content/newslist.md" 5 >}}

## Interns

I'm fortunate to be supervising / have supervised exceptionally strong interns, and always looking to support more students!

- [Peter Tong](https://tsb0601.github.io/petertongsb/), Research Intern @ FAIR, Meta AI 2025-26; Peter also worked with me before, co-supervised with [Mike Rabbat](https://ai.meta.com/people/1148536089838617/michael-rabbat/) and [Zhuang Liu](https://liuzhuang13.github.io/) as a Research Intern @ Meta AI, 2024
- [Weijia Shi](https://weijiashi.notion.site/), Research Intern, FAIR, Meta AI 2025
- [Jiachen Zhu](https://jiachenzhu.github.io/), Visiting Researcher, FAIR, Meta AI 2025
- [Han Lin](https://hl-hanlin.github.io/), Research Intern @ Meta AI, 2024
- [Benno Krojer](https://bennokrojer.github.io/), co-supervised with [Nicolas Ballas](https://scholar.google.com/citations?user=euUV4iUAAAAJ&hl=en) and [Mido Assran](https://www.midoassran.ca/), Research Intern @ Meta AI, 2024
- [Karen Chen](https://jiahuikchen.github.io/), co-supervised with [Adriana Romero Soriano](https://sites.google.com/site/adriromsor/home) and [Michal Drozdal](https://ca.linkedin.com/in/michal-drozdzal-a36b9b42), Research Intern @ Meta AI, 2024
- [Oscar Manas](https://mila.quebec/en/directory/oscar-manas/), co-supervised with [Adriana Romero Soriano](https://sites.google.com/site/adriromsor/home) and [Michal Drozdal](https://ca.linkedin.com/in/michal-drozdzal-a36b9b42), Research Intern @ Meta AI, 2024
- [Bhargavi Paranjape](https://bhargaviparanjape.github.io/), Research Intern @ Meta AI, 2023
- [David Wan](https://meetdavidwan.github.io/), co-supervised with [Ram Pasunuru](http://www.rama-kanth.com/), Research Intern @ Meta AI, 2023
- [Song Jiang](https://songjiang0909.github.io/), co-supervised with [Asli Celikyilmaz](http://asli.us/), Research Intern @ Meta AI, 2023
- [Jake Bremerman](https://www.isi.edu/directory/bremerma/), co-supervised with [Mingda Chen](https://mingdachen.github.io/), Research Intern @ Meta AI, 2023
- [Kumar Shridhar](https://kumar-shridhar.github.io/), co-supervised with [Jason Weston](https://scholar.google.com/citations?user=lMkTx0EAAAAJ&hl=en), Research Intern @ Meta AI, 2023
- [Silin Gao](https://silin159.github.io/SilinGao/), co-supervised with [Tianlu Wang](https://tianlu-wang.github.io/), Research Intern @ Meta AI, 2023
- [Saeed Goodarzi](https://scholar.google.com/citations?user=padFM5wAAAAJ&hl=en), Nikhil Kagita &amp; Dennis Minn, co-supervised with [Adina Williams](https://wp.nyu.edu/adinawilliams/), [Shubham Toshniwal](https://shtoshni.github.io/) and [Jack Lanchatin](https://www.jacklanchantin.com/), [UMass Industry Mentorship Program](https://ds.cs.umass.edu/programs/industry-mentorship-program) with Meta, Summer of 2023

## Invited Talks

- Keynote, [Reproducibility Tutorial](https://miccai2023-reproducibility-tutorial.github.io/), MICCAI 2023
- Panelist, [Reproducibility and Rigor in ML](https://ml-eval.github.io/panels/), ML Evaluation Standards Workshop at ICLR 2022, April 2022
- Evaluating Logical Generalization with Graph Neural Networks, Weights and Biases Salon, ([Online](https://www.youtube.com/watch?v=HllTbhy3WSA)), May 2020
- _ML Reproducibility - From Theory to Practice_, [DL4Science](https://dl4sci-school.lbl.gov/) Seminar, Lawrence Berkeley National Laboratory, Berkeley, ([Online](https://www.youtube.com/watch?v=se7LNICECqI)), August 2020; [MICCAI Hackathon](https://miccai-hackathon.com/), Peru, 2020, October 2020; Bielefield University, Germany, hosted by [Malte Schilling](https://ni.www.techfak.uni-bielefeld.de/people/mschilli), October 2021

## Featured Awards

- **Outstanding Paper Award, ACL 2022**, [Language model acceptability judgements are not always robust to context](https://arxiv.org/abs/2212.08979); _**Koustuv Sinha**, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams_, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022
- **Outstanding Paper Award, ACL 2021**, [UnNatural Language Inference](https://arxiv.org/abs/2101.00010), _**Koustuv Sinha**, Prasanna Parthasarathi, Joelle Pineau, Adina Williams_

## Academic Responsibilities

- Lead organizer, [ML Reproducibility Challenge](https://reproml.org/) : ([v1](https://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html),
  [v2](https://www.cs.mcgill.ca/~jpineau/ICLR2019-ReproducibilityChallenge.html),
  [v3](https://reproducibility-challenge.github.io/neurips2019/),
  [v4](https://paperswithcode.com/rc2020),
  [v5](https://paperswithcode.com/rc2021),
  [v6](https://paperswithcode.com/rc2022), [v7](https://reproml.org/proceedings/mlrc2023/), [v8](https://reproml.org/call_for_papers/))
- Senior Area Chair: [ACL 2024](https://2024.aclweb.org/)
- Area Chair: COLM 2025, ACL ARR May 2025, ACL ARR February 2025 (ACL 2025), ACL ARR December 2024, ACL ARR June 2024
- Journal Chair: NeurIPS 2022
- Reproducibility Chair: NeurIPS 2019, NeurIPS 2020
- Reviewer: ACL ARR Cycle Reviewer, ICCV 2025, CVPR 2025, NeurIPS 2024, COLM 2024, and many more ...

## Contact

Best place to reach out to me is through email. I'm on social media platforms but I rarely monitor them.

- `{firstname}.{lastname}@{mail.mgill.ca}` / `{firstnamelastname}@{gmail.com}`
- [BlueSky](https://bsky.app/profile/koustuvsinha.com) | [Twitter/X](https://twitter.com/koustuvsinha) | [LinkedIn](https://www.linkedin.com/) | [Github](https://github.com/koustuvsinha)

<!-- **XMin** is a Hugo theme written by [Yihui Xie](https://yihui.org) in about four hours: half an hour was spent on the Hugo templates, and 3.5 hours were spent on styling. The main motivation for writing this theme was to provide a really minimal example to beginners of Hugo templates. This XMin theme contains about 140 lines of code in total, including the code in HTML templates and CSS (also counting empty lines). -->
<!---->
<!-- ```bash -->
<!-- find . -not -path '*/exampleSite/*' \( -name '*.html' -o -name '*.css' \) | xargs wc -l -->
<!-- ``` -->
<!---->
<!-- ``` -->
<!--        5 ./layouts/404.html -->
<!--       12 ./layouts/_default/single.html -->
<!--       20 ./layouts/_default/list.html -->
<!--       13 ./layouts/_default/terms.html -->
<!--        0 ./layouts/partials/foot_custom.html -->
<!--        0 ./layouts/partials/head_custom.html -->
<!--        9 ./layouts/partials/footer.html -->
<!--       20 ./layouts/partials/header.html -->
<!--       51 ./static/css/style.css -->
<!--        7 ./static/css/fonts.css -->
<!--      137 total -->
<!-- ``` -->
<!---->
<!-- I can certainly further reduce the code, for example, by eliminating the CSS, but I believe a tiny bit of CSS can greatly improve readability. You cannot really find many CSS frameworks that only contain 50 lines of code. -->
<!---->
<!-- Although it is a minimal theme, it is actually fully functional. It supports pages (including the home page), blog posts, a navigation menu, categories, tags, and RSS. With [a little bit customization](https://github.com/yihui/hugo-xmin/blob/master/exampleSite/layouts/partials/foot_custom.html), it can easily support LaTeX math expressions, e.g., -->
<!---->
<!-- $${\sqrt {n}}\left(\left({\frac {1}{n}}\sum _{i=1}^{n}X_{i}\right)-\mu \right)\ {\xrightarrow {d}}\ N\left(0,\sigma ^{2}\right)$$ -->
<!---->
<!-- All pages not under the root directory of the website are listed below. You can also visit the list page of a single section, e.g., [posts](/post/), or [notes](/note/). See the [About](/about/) page for the usage of this theme. -->
