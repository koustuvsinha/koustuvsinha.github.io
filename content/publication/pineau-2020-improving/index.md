---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS
  2019 Reproducibility Program)
subtitle: ''
summary: ''
authors:
- Joelle Pineau
- Philippe Vincent-Lamarre
- Koustuv Sinha
- Vincent Larivière
- Alina Beygelzimer
- Florence d'Alché-Buc
- Emily Fox
- Hugo Larochelle
tags: []
categories: []
date: '2020-01-01'
lastmod: 2022-07-18T19:57:58-04:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-07-18T23:57:58.532714Z'
publication_types:
- '2'
abstract: 'One of the challenges in machine learning research is to ensure that presented
  and published results are sound and reliable. Reproducibility, that is obtaining
  similar results as presented in a paper or talk, using the same code and data (when
  available), is a necessary step to verify the reliability of research findings.
  Reproducibility is also an important step to promote open and accessible research,
  thereby allowing the scientific community to quickly integrate new findings and
  convert ideas to practice. Reproducibility also promotes the use of robust experimental
  workflows, which potentially reduce unintentional errors. In 2019, the Neural Information
  Processing Systems (NeurIPS) conference, the premier international conference for
  research in machine learning, introduced a reproducibility program, designed to
  improve the standards across the community for how we conduct, communicate, and
  evaluate machine learning research. The program contained three components: a code
  submission policy, a community-wide reproducibility challenge, and the inclusion
  of the Machine Learning Reproducibility checklist as part of the paper submission
  process. In this paper, we describe each of these components, how it was deployed,
  as well as what we were able to learn from this initiative.'
publication: '*Journal of Machine Learning Research (JMLR)*'
links:
- name: JMLR
  url: https://jmlr.org/papers/v22/20-303.html
---
