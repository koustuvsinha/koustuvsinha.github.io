<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Fira+Sans:wght@400;700&family=Roboto+Mono&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Fira+Sans:wght@400;700&family=Roboto+Mono&display=swap" media=print onload='this.media="all"'><meta name=author content="Koustuv Sinha"><meta name=description content="Introduction It has been three years since the release of CLUTRR, a benchmark we created to test the reasoning capabilities of modern neural networks. The idea is simple: can models understand first-order logic, in the backdrop of kinship relations?"><link rel=alternate hreflang=en-us href=https://koustuvsinha.com/post/zero_shot_clutrr/><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.99ecbdcb5f73ec1ef08ee51f9bf420b0.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://koustuvsinha.com/post/zero_shot_clutrr/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@koustuvsinha"><meta property="twitter:creator" content="@koustuvsinha"><meta property="og:site_name" content="Koustuv Sinha"><meta property="og:url" content="https://koustuvsinha.com/post/zero_shot_clutrr/"><meta property="og:title" content="LLMs can sanitize annotations! Using zero shot relation extraction to fix CLUTRR templates | Koustuv Sinha"><meta property="og:description" content="Introduction It has been three years since the release of CLUTRR, a benchmark we created to test the reasoning capabilities of modern neural networks. The idea is simple: can models understand first-order logic, in the backdrop of kinship relations?"><meta property="og:image" content="https://koustuvsinha.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://koustuvsinha.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-12-23T17:45:00-05:00"><meta property="article:modified_time" content="2022-12-23T17:45:00-05:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://koustuvsinha.com/post/zero_shot_clutrr/"},"headline":"LLMs can sanitize annotations! Using zero shot relation extraction to fix CLUTRR templates","datePublished":"2022-12-23T17:45:00-05:00","dateModified":"2022-12-23T17:45:00-05:00","author":{"@type":"Person","name":"Koustuv Sinha"},"publisher":{"@type":"Organization","name":"Koustuv Sinha","logo":{"@type":"ImageObject","url":"https://koustuvsinha.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"}},"description":"Introduction It has been three years since the release of CLUTRR, a benchmark we created to test the reasoning capabilities of modern neural networks. The idea is simple: can models understand first-order logic, in the backdrop of kinship relations?"}</script><title>LLMs can sanitize annotations! Using zero shot relation extraction to fix CLUTRR templates | Koustuv Sinha</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=861d7a9cf92be60396abb3c9140fb4e9><script src=/js/wowchemy-init.min.df5b75624ac8e15e4f78f4316a963728.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Koustuv Sinha</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Koustuv Sinha</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class="nav-link active" href=/post><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/activities><span>Activities</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class="article article-project"><div class="article-container pt-3"><h1>LLMs can sanitize annotations! Using zero shot relation extraction to fix CLUTRR templates</h1><div class=article-metadata><span class=article-date>Dec 23, 2022</span>
<span class=middot-divider></span>
<span class=article-reading-time>11 min read</span></div></div><div class=article-container><div class=article-style><h2 id=introduction>Introduction</h2><p>It has been three years since the release of <a href=/introducing-clutrr/>CLUTRR</a>, a benchmark we created to test the reasoning capabilities of modern neural networks. The idea is simple: can models understand first-order logic, in the backdrop of kinship relations? Specifically, we test the ability of the models to perform <em>implicit</em> reasoning - figuring out the relation of two characters in a given story, where their relation is not provided explicitly. For example, consider the following story:</p><blockquote><p>Linda and her sister Stacy disagreed about what to make for dinner. Linda thought they should make meatloaf, while Stacy thought they should make ham, because it was her son Robert&rsquo;s favorite.</p><p>Q: Linda is the _ of Robert.</p></blockquote><p>The correct answer of the above question is &ldquo;aunt&rdquo;, which is not stated explicitly in the text. This is obvious because we can internally compute the following <em>composition</em> of relations:</p><p>\(A = \mathcal{R}(\text{Robert}, \text{Stacy}) \land \mathcal{R}(\text{Stacy}, \text{Linda})\)</p><p>where, \(\mathcal{R}\) is the function to extract the relation, and we get the following <em>facts</em>: &ldquo;Stacy is the <em>mother</em> of Robert&rdquo;, and &ldquo;Linda is the <em>sister</em> of Stacy&rdquo;. Combining both, we get &ldquo;Linda is the <em>aunt</em> of Robert&rdquo;.</p><p>The use-case of CLUTRR is that we can test for arbitrarily large number of such combinations, and therefore test a models ability to do <em>length generalizaiton</em> - testing its reasoning abilities in problems <em>longer</em> or <em>shorter</em> than the ones it has been trained. Theoretically, if a <em>systematic learner</em> is exposed to all possible binary compositions of relations, it can extrapolate or interpolate with ease.</p><p>What we found back those many years ago, is that then neural models (LSTMs, RNNs, MACs, BERT) were unable to perform length generalization. Since then, there has been <a href=https://arxiv.org/abs/2007.06477 target=_blank rel=noopener>numerous</a> <a href=https://arxiv.org/abs/2112.00578 target=_blank rel=noopener>papers</a> published which used CLUTRR to test the compositional generalization abilities of the models proposed, and improved the state-of-the-art significantly. However, length generalization still remains an <a href=https://arxiv.org/abs/2207.04901v2 target=_blank rel=noopener>elusive problem</a> for modern neural networks, and a combination of factors are needed to make it work.</p><h2 id=the-issue-with-templates>The issue with templates</h2><p>Over the last several months, I have received feedback from the community that several data points in CLUTRR contain <a href=https://github.com/facebookresearch/clutrr/issues/15 target=_blank rel=noopener>glaring issues</a> - they contain incorrect kinship-relation logic! For example, consider this data highlighted by Github user zhunyoung:</p><blockquote><p>[Kathleen] was excited because she was meeting her father, [Henry], for lunch. [Howard] and his son [Wayne] went to look at cars. [Howard] ended up buying the Mustang. [Howard] likes to spend time with his aunt, [Kathleen], who was excellent at cooking chicken.</p><p>Q: Henry is the _ of Wayne. A: father</p></blockquote><p>As the zhunyoung correctly points out, this is incorrect as the answer should be <em>&ldquo;great-grandfather&rdquo;</em> instead. Now the question is, how did the CLUTRR generator end up with this incorrect example, if it is built using the principles of first-order logic?</p><p>At its core, CLUTTR consists of entity-relation pairs which is built using a fixed set of <a href=https://github.com/koustuvsinha/glc/blob/386cfb036a37aa65d29c7dbde01f70f067f03890/rule_bases/clutrr_0.json target=_blank rel=noopener>logical rules</a>. By recursively applying these rules, arbitrarily complex chains of conjunction &ldquo;paths&rdquo; can be created. This entity-relation chain is then converted to semi-synthetic language by applying templated stories. The basic version only contains the template : <code>E2 is the {relation} of E1</code>, where <code>E1</code> and <code>E2</code> are the entities. Replacing the template with entity names, CLUTRR generates compositional puzzles of the following form:</p><blockquote><p>Linda is the sister of Stacy. Robert is the son of Linda.</p><p>Q: Linda is the _ of Robert.</p></blockquote><p>However, it is clear this basic templating version would be easy enough for the models to reason on, as the input lacks complex natural language formulations, and sidesteps the problem of entity resolution, coreference resolution and relation extraction. Thus in CLUTRR, we collected a bunch of human-written stories to be the templates. These stories are written by Amazon Mechanical Turkers &ldquo;turkers&rdquo; when they are provided with a family relation tree (set of entities and relations between them). During generation of the data, we dynamically select these templates and stitch them together to construct the data (see our paper for more details).</p><p>Given the error pointed out by zhunyoung, it is likely that some of these human-written templates are incorrectly written. Digging a bit into the collected templates, surely I found the issue - the template used in zhunyoung&rsquo;s example is collected wrong:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;template&#34;</span><span class=p>:</span> <span class=s2>&#34;ENT_1_male and his son ENT_0_male went to look at cars. ENT_1_male ended up buying the Mustang.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;rel_comb&#34;</span><span class=p>:</span> <span class=s2>&#34;son&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;gender_comb&#34;</span><span class=p>:</span> <span class=s2>&#34;male-male&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The way the data is defined, <code>rel_comb</code> states the explicit relationship between the two entities, such that we can fill in the blanks: &ldquo;entity 2 is the <code>rel_comb</code> of entity 1&rdquo;. Clearly, in this example, <code>ENT_1_male</code> is not the <code>son</code> of <code>ENT_0_male</code>, rather he is the <code>father</code> of <code>ENT_0_male</code>. This is a case of <em>role-swapping</em>.</p><p>So what exactly happened here? During data collection, the turker must had exchanged the <em>order</em> of the provided entities and written the story. If we swap <code>ENT_0_male</code> and <code>ENT_1_male</code> in the above example, the issue is fixed!</p><p>Interestingly though, none of the published papers on CLUTRR use this Amazon Mechanical Turk version of templates - they tend to use the basic templated version of the data. Now it is more clear why - the AMT data has issues we need to fix!</p><h2 id=searching-the-templates-for-issues>Searching the templates for issues</h2><p>Now we have an idea of the type of issue that could be present in the data. The next step is the figure out <em>how many</em> templates are affected by this. We have close to 5000 templates, so manually annotating them alone would take a lot of time for me. Thus, I opted for the second best option - writing a Python script to find the errors.</p><p>Turns out this is a hard problem - my script needs to run coreference resolution and then perform reliable <em>relation extraction</em> from the collected templates. The problem is even more acute as we collected free-form stories - there is no fixed structure among the templates for easy extraction.</p><p>Nevertheless, my first attempt to build a simple pipeline involving a coreference resolver, and subsequent dependency tree extraction failed miserably. I use <a href=https://spacy.io/usage/linguistic-features target=_blank rel=noopener>spacy</a> and <a href=https://github.com/msg-systems/coreferee target=_blank rel=noopener>coreferee</a> libraries to extract the dependency tree and resolving coreferences. Comparing the predicted relations in the data, this method achieves a mere <strong>34.6%</strong> accuracy!</p><p>Surely the AMT templates are not <em>this</em> bad! Time to invest in a better relation extraction pipeline.</p><p>Next, I turn to a state-of-the-art relation extractor to do its job. The <a href=https://github.com/thunlp/OpenNRE target=_blank rel=noopener>OpenNRE project</a> looked interesting - it is a neural model trained on NYT and Wikipedia datasets. The goal of this project is to perform <em>implicit</em> <a href=https://aclanthology.org/D19-3029.pdf target=_blank rel=noopener>relation extraction</a>, on multiple relation types. I ran the inference pipeline with <code>wiki80_bert_softmax</code> model on the CLUTRR train and test set. This also required a little bit of post-processing, as it always clubs the relations &ldquo;son&rdquo; and &ldquo;daughter&rdquo; to <code>child</code>, and &ldquo;brother&rdquo; and &ldquo;sister&rdquo; to <code>sibling</code>. This should extract the explicit relations easily, right?</p><p>Sadly, the relation extractor is only able to get ~30% of the labels correctly, which is even worse than my naive data extractor. Is the problem too complex, or the majority of templates has issues?</p><h2 id=relation-extraction-using-zero-shot-prompting>Relation extraction using zero-shot prompting</h2><p>Over the last couple of weeks, <a href=https://chat.openai.com/chat target=_blank rel=noopener>ChatGPT</a> has taken the world by storm given how accurate its responses are! Surely it should be <strong>much</strong> better at extracting relations? I tested a couple of templates out:</p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/chatgpt_clutrr_explicit.png alt loading=lazy data-zoomable></div></div></figure><p>It is able to perfectly extract the explicit relation! Heck, it is even able to extract the implicit relation of <em>aunt</em>!</p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/chatgpt_clutrr_implicit.png alt loading=lazy data-zoomable></div></div></figure><p>It is too bad ChatGPT doesn&rsquo;t have an API to run the relation extractions <em>en-masse</em>. But it is clear some form of instruction-tuning would be able to extract the relations with a simple enough prompt. To test my hypothesis, I started with an openly available model - <a href=https://huggingface.co/docs/transformers/model_doc/flan-t5 target=_blank rel=noopener>FlanT5</a> from <a href=https://arxiv.org/pdf/2210.11416.pdf target=_blank rel=noopener>Google</a>, which is conveniently available on Huggingface, along with multiple model scales. I used the <code>flan-t5-xl</code> model as it is the largest model which fits in my GPU without having to run inference on half precision <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>The results are quite good! <code>flan-t5-xl</code> gets <strong>74.4%</strong> and <strong>71.6%</strong> correct labels in the train and test splits! This is a more reasonable score, which basically says about 26-29% of the template is either incorrect or too hard for FlanT5 to reason correctly.</p><p>How about using a better model? <a href=https://beta.openai.com/ target=_blank rel=noopener>OpenAI</a> recently released the instruction-finetuned version of <a href=https://arxiv.org/abs/2005.14165 target=_blank rel=noopener>GPT3</a>, <code>text-davinci-003</code>. GPT3 is a 175B parameter model, and this recent updated model is fine-tuned over a lot of instruction-oriented datasets so that is has good zero-shot and few-shot capabilities.</p><p>Turns out, it does get a little bit better than FlanT5: <strong>77.97%</strong> and <strong>78.47%</strong> on the train and test splits. This further reduces the error range to 21-22%, indicating the remaining templates needs to be analysed for potential annotation issues.</p><h2 id=error-analysis>Error analysis</h2><p>Now, let us dig deeper into the errors, to find what kind of annotation errors are present in the templates. The CLUTRR AMT templates are three types: templates with two entities and one relation, templates with three entities and two relations, and templates with four entities with three relations. We first see the error % in these three buckets:</p><table><thead><tr><th>Split</th><th>Relations</th><th><code>flan-t5-xl</code></th><th><code>text-davinci-003</code></th></tr></thead><tbody><tr><td>Train</td><td>1</td><td>89.92</td><td>91.36</td></tr><tr><td></td><td>2</td><td>84.86</td><td>79.76</td></tr><tr><td></td><td>3</td><td>57.63</td><td>68.72</td></tr><tr><td>Test</td><td>1</td><td>87.5</td><td>89.74</td></tr><tr><td></td><td>2</td><td>83.89</td><td>85.57</td></tr><tr><td></td><td>3</td><td>55.41</td><td>68.01</td></tr></tbody></table><p>Not surprisingly, templates with three relations are hardest for the model to extract relations, as the story is long and complicated. Interestingly, this is where GPT3 outperforms FlanT5 by a large margin. However, FlanT5 is able to get better performance in the train set for two relations (with three entities).</p><p>Now, to evaluate the errors, I first <a href="https://docs.google.com/spreadsheets/d/1pn1pjLbEmqbaJqm5Ya81DEv7TnYRv3Wl9InbjlxiT2Y/edit?usp=sharing" target=_blank rel=noopener>manually annotate</a> 127 templates of single relation templates where Flan T5 gets it incorrect. In these, I find only <strong>23%</strong> of templates having annotation errors. Of these, 75% of errors are due to the role swapping. Thus, a majority of the incorrectly classified templates are actually quite hard for the zero shot models to predict, while the rest of them can be either fixed by swapping the relations of the affected entities or dropping them altogether.</p><h2 id=releasing-the-gpt3-cleaned-data-clutrr-v1-dot-3>Releasing the GPT3 cleaned data: CLUTRR v1.3</h2><p>I&rsquo;m continually amazed at how far these large language models have progressed in the field, to the point they can perform complex tasks such as relation extraction with ease! Thanks to the instruction-tuned models GPT3 and FlanT5, I do not have to manually annotate thousands of data points. There is a slight possibility of false positives though, which would unfortunately require a full manual annotation with multiple annotators to verify. If you find an error with GPT3 annotated templates, feel free to open a PR to fix that! <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><p>I have been working to streamline the generation process for CLUTRR for a while (<a href=https://github.com/facebookresearch/clutrr/tree/develop target=_blank rel=noopener><code>develop</code></a> branch). To make the generation process faster, the graph generator is now maintained separately in <a href=https://github.com/koustuvsinha/glc target=_blank rel=noopener>GLC</a> repository, which is also used by another related project, <a href=https://github.com/facebookresearch/GraphLog target=_blank rel=noopener>GraphLog</a>. The changes in the AMT templates as described above are now released in <a href=https://github.com/facebookresearch/clutrr/tree/develop target=_blank rel=noopener>version 1.3</a>, which adds the capability of choosing a subset of AMT templates for application. Additionally, if you wish to skip a specific template from the generation, you can set a flag in the configs during the generation process. I plan to merge the develop branch to main branch once we are ready for version 2.0.</p><h2 id=roadmap-for-clutrr-2-dot-0>Roadmap for CLUTRR 2.0</h2><p>When we released CLUTRR we were just witnessing the power of large pre-trained models (BERT was released a few months prior). Now, the scenario in NLP has changed drastically with massive language models (GPT3, OPT) demonstrating a suprising ability - the ability to perform &ldquo;zero-shot&rdquo; reasoning and to learn &ldquo;in-context&rdquo;, removing the need to learn the model weights (fine-tuning) on a specific task. This paradigm-shift in training/evaluating models will be a core research area in the coming years, with a renewed focus on <em>reasoning</em>. GPT3/ChatGPT, with all its massive number of weights, are still <a href=https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html target=_blank rel=noopener>poor</a> on arithmetic and logical reasoning.</p><p>Thus, it is important to test a models ability on logical reasoning, and also to perform compositional generalization on longer sequences (length generalization). Also, several exciting methods have emerged over the past year (<a href=https://arxiv.org/abs/2201.11903 target=_blank rel=noopener>chain-of-thought</a> (CoT), <a href=https://arxiv.org/abs/2112.00114v1 target=_blank rel=noopener>scratchpads</a>) which allow the model to perform better reasoning by providing <em>explanations</em>. CLUTRR is well positioned to test these, as CLUTRR v1.3 already supports the generation of intermediate proof steps, which can be useful with these methods to evaluate/train LLMs to perform logical reasoning. In the next major release, CLUTRR 2.0, we would be explicitly developing benchmarks and methods focusing on these areas. <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> If you would like to be involved or chat more about the possibilities of CLUTRR 2.0, feel free to drop me a mail!</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>For some reason I&rsquo;m getting way worse results on fp16 with FlanT5. Curious to know why that is the case.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>The code for the experiments and analysis in this post is available at this <a href="https://colab.research.google.com/drive/1futiS931teG76OBlwYElMrR4R4ZwjvBu?usp=sharing" target=_blank rel=noopener>Google Colab File</a>. The code to run the zero shot experiments are given in this <a href=https://gist.github.com/koustuvsinha/555051d2112fd999ff1159436cadfd07 target=_blank rel=noopener>Github Gist</a>. Data annotations by Flan T5 and GPT3 is <a href=https://github.com/facebookresearch/clutrr/tree/develop/clutrr/templates/amt target=_blank rel=noopener>also released here</a> if you want to inspect further.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>While drafting this blog post I came across this very <a href=https://arxiv.org/abs/2212.08686 target=_blank rel=noopener>relevant preprint</a>, which shows in CLUTRR CoT can be outperformed handsomely by equivalent neuro-symbolic prompting methods.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://koustuvsinha.com/post/zero_shot_clutrr/&text=LLMs%20can%20sanitize%20annotations!%20Using%20zero%20shot%20relation%20extraction%20to%20fix%20CLUTRR%20templates" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://koustuvsinha.com/post/zero_shot_clutrr/&t=LLMs%20can%20sanitize%20annotations!%20Using%20zero%20shot%20relation%20extraction%20to%20fix%20CLUTRR%20templates" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=LLMs%20can%20sanitize%20annotations!%20Using%20zero%20shot%20relation%20extraction%20to%20fix%20CLUTRR%20templates&body=https://koustuvsinha.com/post/zero_shot_clutrr/" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://koustuvsinha.com/post/zero_shot_clutrr/&title=LLMs%20can%20sanitize%20annotations!%20Using%20zero%20shot%20relation%20extraction%20to%20fix%20CLUTRR%20templates" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=LLMs%20can%20sanitize%20annotations!%20Using%20zero%20shot%20relation%20extraction%20to%20fix%20CLUTRR%20templates%20https://koustuvsinha.com/post/zero_shot_clutrr/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://koustuvsinha.com/post/zero_shot_clutrr/&title=LLMs%20can%20sanitize%20annotations!%20Using%20zero%20shot%20relation%20extraction%20to%20fix%20CLUTRR%20templates" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://koustuvsinha.com/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hucc78bc830b96374f35a67d0f4452e819_1023205_270x270_fill_q75_lanczos_center.jpg alt="Koustuv Sinha"></a><div class=media-body><h5 class=card-title><a href=https://koustuvsinha.com/>Koustuv Sinha</a></h5><h6 class=card-subtitle>Research Scientist</h6><p class=card-text>My research interests include natural language processing with machine learning, computational linguistics and interpretable machine learning. I organize the annual <a href=https://paperswithcode.com/rc2021 target=_blank rel=noopener>ML Reproducibility Challenge</a>.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/koustuvsinha target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=9P9QcckAAAAJ" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/koustuvsinha target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><section id=comments><script src=https://utteranc.es/client.js repo=koustuvsinha/koustuvsinha.github.io issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></section><div class="project-related-pages content-widget-hr"></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2022 Koustuv Sinha. This website is built using <a href=https://ox-hugo.scripter.co/ target=_blank rel=noopener>ox-hugo</a>, <a href=https://orgmode.org/ target=_blank rel=noopener>org-mode</a>, <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> and <a href=https://wowchemy.com/ target=_blank rel=noopener>Wowchemy</a>, on Emacs 28.1. Opinions expressed in this website are solely my own. While we strive for excellence in research, it is important to remember that <a href=https://www.facebook.com/nipsfoundation/videos/2120856364798049/ target=_blank rel=noopener><em>&ldquo;Science is not a competitive sport&rdquo;</em></a>.</p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.992ab4bf929c75fb2aff9ec73febac85.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>