@misc{sharma2021evaluating,
 abstract = {Gender-bias stereotypes have recently raised significant
ethical concerns in natural language processing. However,
progress in the detection and evaluation of gender-bias in
natural language understanding through inference is limited
and requires further investigation. In this work, we propose
an evaluation methodology to measure these biases by
constructing a probe task that involves pairing a
gender-neutral premise against a gender-specific hypothesis.
We use our probe task to investigate state-of-the-art NLI
models on the presence of gender stereotypes using
occupations. Our findings suggest that three models (BERT,
RoBERTa, and BART) trained on MNLI and SNLI data-sets are
significantly prone to gender-induced prediction errors. We
also find that debiasing techniques such as augmenting the
training dataset to ensure that it is a gender-balanced
dataset can help reduce such bias in certain cases.},
 author = {Sharma, Shanya and Dey, Manan and Sinha, Koustuv},
 title = {Evaluating Gender Bias in Natural Language Inference },
 url = {https://openreview.net/forum?id=bnuU0PzXl0-},
 year = {2021}
}

