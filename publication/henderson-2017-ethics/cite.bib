@article{henderson2017ethics,
 abstract = {The use of dialogue systems as a medium for human-machine
interaction is an increasingly prevalent paradigm. A growing
number of dialogue systems use conversation strategies that
are learned from large datasets. There are well documented
instances where interactions with these system have resulted
in biased or even offensive conversations due to the
data-driven training process. Here, we highlight potential
ethical issues that arise in dialogue systems research,
including: implicit biases in data-driven systems, the rise of
adversarial examples, potential sources of privacy violations,
safety concerns, special considerations for reinforcement
learning systems, and reproducibility concerns. We also
suggest areas stemming from these issues that deserve further
investigation. Through this initial survey, we hope to spur
research leading to robust, safe, and ethically sound dialogue
systems.},
 arxiv = {1711.09050},
 author = {Henderson, Peter and Sinha, Koustuv and
Angelard-Gontier, Nicolas and Ke, Nan Rosemary and
Fried, Genevieve and Lowe, Ryan and Pineau, Joelle},
 code = {https://github.com/Breakend/EthicsInDialogue},
 journal = {AAAI/ACM AI Ethics and Society Conference},
 title = {Ethical Challenges in Data-Driven Dialogue Systems},
 year = {2018}
}

