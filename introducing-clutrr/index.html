<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Fira+Sans:wght@400;700&family=Roboto+Mono&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Fira+Sans:wght@400;700&family=Roboto+Mono&display=swap" media=print onload='this.media="all"'><meta name=author content="Koustuv Sinha"><meta name=description content="Compositional Language Understanding with Text based Relational Reasoning
Motivation Question Answering (QA) has recently gained popularity as the major domain of testing reasoning in text. The literature thus contains a deluge of Question Answering (QA) datasets to choose from."><link rel=alternate hreflang=en-us href=/introducing-clutrr/><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.99ecbdcb5f73ec1ef08ee51f9bf420b0.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><link rel=canonical href=/introducing-clutrr/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@koustuvsinha"><meta property="twitter:creator" content="@koustuvsinha"><meta property="og:site_name" content="Koustuv Sinha"><meta property="og:url" content="/introducing-clutrr/"><meta property="og:title" content="Introducing CLUTRR | Koustuv Sinha"><meta property="og:description" content="Compositional Language Understanding with Text based Relational Reasoning
Motivation Question Answering (QA) has recently gained popularity as the major domain of testing reasoning in text. The literature thus contains a deluge of Question Answering (QA) datasets to choose from."><meta property="og:image" content="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2019-09-07T00:00:00+00:00"><meta property="article:modified_time" content="2019-09-07T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/introducing-clutrr/"},"headline":"Introducing CLUTRR","datePublished":"2019-09-07T00:00:00Z","dateModified":"2019-09-07T00:00:00Z","author":{"@type":"Person","name":"Koustuv Sinha"},"publisher":{"@type":"Organization","name":"Koustuv Sinha","logo":{"@type":"ImageObject","url":"/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"}},"description":"Compositional Language Understanding with Text based Relational Reasoning\nMotivation Question Answering (QA) has recently gained popularity as the major domain of testing reasoning in text. The literature thus contains a deluge of Question Answering (QA) datasets to choose from."}</script><title>Introducing CLUTRR | Koustuv Sinha</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=66874b7ef3bc8ad03258e3919212dec2><script src=/js/wowchemy-init.min.df5b75624ac8e15e4f78f4316a963728.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Koustuv Sinha</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Koustuv Sinha</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/post><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/activities><span>Activities</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class="article article-project"><div class="article-container pt-3"><h1>Introducing CLUTRR</h1><div class=article-metadata><span class=article-date>Sep 7, 2019</span>
<span class=middot-divider></span>
<span class=article-reading-time>10 min read</span></div></div><div class=article-container><div class=article-style><p><b>C</b>ompositional <b>L</b>anguage <b>U</b>nderstanding with <b>T</b>ext based <b>R</b>elational <b>R</b>easoning</p><h2 id=motivation>Motivation</h2><p>Question Answering (QA) has recently gained popularity as the major
domain of testing reasoning in text. The literature thus contains a
<a href=https://nlpprogress.com/english/question_answering.html target=_blank rel=noopener>deluge of Question Answering (QA) datasets</a> to choose from. These datasets test
the system&rsquo;s ability to extract factual answers from the text. However,
there are growing concerns regarding the ability of Natural Language
Understanding (NLU) models to <strong>generalize</strong> - both in a <em>systematic</em> and
<em>robust</em> way. Adding to that, the recent dominance of large pre-trained
language models (such as BERT, <a href=https://arxiv.org/abs/1810.04805 target=_blank rel=noopener>Devlin et al. 2018</a>) on many NLU
benchmarks including QA suggests that the primary difficulty in these
datasets are about incorporating the statistics of the language, or the
syntax of the language, rather than pure reasoning.</p><p>We want to develop systems which perform reasoning <em>inductively</em>,
i.e. not only by pure extraction of text facts but by performing a
higher-order reasoning and drawing conclusions based on <em>evidence</em>.
Ideally, we also want the systems to <em>generalize</em> on unseen
distributions, as well as be <em>robust</em> to adversarial attacks. To
facilitate that research, we present our diagnostic suite &ldquo;<code>CLUTRR</code>&rdquo;.</p><h2 id=overview>Overview</h2><p>Our benchmark suite <code>CLUTRR</code> contains a large set of semi-synthetic
stories involving hypothetical families. Given a story, the goal is to
infer the relationship between two family members, whose relationship is
not explicitly mentioned.</p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/clutrr_text.png alt loading=lazy data-zoomable></div></div></figure><p>To solve this task, an agent must extract the <em>logical rules</em> governing
the composition of the relationships (e.g. the transitivity of the
sibling relations). The benchmark allows us to test the learning agent&rsquo;s
ability for <em>systematic generalization</em> by testing on stories that
contain unseen combinations of logical rules. It also allows us to
precisely test for the various forms of <em>model robustness</em> by adding
different kinds of superfluous <em>noise facts</em> to the stories.</p><h2 id=dataset-construction>Dataset Construction</h2><p>To derive a dataset which provides an effective way to test
generalization and robustness, we looked into classical Logic.
<a href=https://www.doc.ic.ac.uk/~shm/ilp.html target=_blank rel=noopener>Inductive Logic Programming</a>
(ILP) is a vast field of work which tries to solve the exact problem of
inductively inferring rules from a given set of data, and one of the
classical examples in the field is deducing kinship relations. For
example, given the facts:</p><ul><li><em>&ldquo;Alice is Bob&rsquo;s mother&rdquo;</em></li><li><em>&ldquo;Jim is Alice&rsquo;s father&rdquo;</em></li></ul><p>one can infer with reasonable certainty that:</p><ul><li><em>&ldquo;Jim is Bob&rsquo;s grandfather&rdquo;</em></li></ul><p>While this may appear trivial to us, it is a challenging task to design
models that can learn from the data to <em>induce</em> the logical rules
necessary to make such inferences. For the above example, the system
needs to learn the rule:</p><p>\[
[\texttt{grandfatherOf},X,Y] \vdash [[\texttt{fatherOf},X,Z], [\texttt{fatherOf}, Z,Y]]
\]</p><p>In ILP, a subset of the above rules was provided as <em>background
knowledge</em> to the system. The system then used to generate higher-order
of rules by recombining existing rules and validating it with the given
data.</p><p>Inspired by this classic task, we set upon building a QA task where
<em>each story is grounded with a logical rule</em>. The core idea being that
each story would describe a set of natural language relations, and the
target is to infer the relationship between two entities whose
relationship <strong>is not explicitly stated</strong> in the story.</p><p>To generate such a story, we first design a knowledge base (KB) of valid
relation compositions for the kinship world. In practice, we used a set
of <a href=https://github.com/facebookresearch/clutrr/blob/master/clutrr/store/rules_store.yaml target=_blank rel=noopener>15 simple rules</a> by carefully avoiding possible ambiguities (such as
relations derived from in-laws). Using these set of rules, we generate
the underlying <em>kinship graph</em>, i.e. a graph containing the kinship
relations about a toy family.</p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/dataset_const_new.png alt loading=lazy data-zoomable></div></div></figure><p>From this kinship graph, we sample an <em>edge</em> which becomes our target
relation to predict. Recall, since we used <em>logical rules</em> to derive
this graph, a path or walk in the graph from a source to sink
constitutes a valid logical rule or <em>clause</em>. We simply sample such a
path of length \(k\), where \(k\) is the tunable parameter for the
data generation.</p><h2 id=adding-language>Adding Language</h2><p>Given this sampled path \(G_p\), we aim to convert this into
<em>semi-synthetic</em> text. The naive way would be to just replace each edge
in the path by a placeholder text explaining the relationship between
them. Consider the example provided in the above figure. The path
\[ B \rightarrow A \rightarrow D \rightarrow G \] can be replaced by the
following text:</p><ul><li>\[ B \rightarrow A \] : B is the wife of A</li><li>\[ A \rightarrow D \] : D is the daughter of A</li><li>\[ D \rightarrow G \] : D is the mother of G</li></ul><p>However, as you can see it already, this ends up to a very artificial
dataset having less linguistic variation. Thus, to reduce the artificial
flavor, we asked <a href=https://parl.ai/docs/tutorial_mturk.html target=_blank rel=noopener>Amazon
Mechanical Turkers</a> to provide us paraphrases for entire sampled paths.
The above example then converts to:</p><blockquote><p>A went to shopping with her wife B at the local grocery store. His
daughter, D, is visiting them for thanksgiving with her daughter G.</p></blockquote><p>This adds extra levels of complexity in the task : co-reference
resolution, dependency parsing and named entity recognition.</p><p>In practice, it became difficult to collect paraphrases of <em>all</em>
possible paths of unbounded lengths. Turkers need active attention to
paraphrase each path, and futhermore increasing path length increases
the number of combinations of relations, leading to larger and larger
number of unique paths. Thus, we collected paraphrases for all possible
combinations till \(k=3\), and we <strong>re-use</strong> paraphrases to stitch
together a story. We collect 6,016 unique paraphrases with an average of
19 paraphrases for every possible logical clause of length
\(k = 1,2,3\).</p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/composition.png alt loading=lazy data-zoomable></div></div></figure><p>From the above example, we see that the stochasticity of dataset
generation provides multiple ways of stitching paraphrases to generate
stories. While the topicality of different paraphrases might impact
coherence of the story, the stitched story remains logically grounded
with respect to kinship relations, and maintains the aspects of
co-reference resolution.</p><h2 id=question-task>Question & Task</h2><p>Thus, given a logically grounded story \(S\) , the question simply boils down to the <em>target edge</em>, i.e. the source and sink. We refrained
from using a &ldquo;natural language&rdquo; question following the insightful
discoveries of <a href=https://arxiv.org/abs/1808.04926 target=_blank rel=noopener>Kaushik & Lipton,
(EMNLP 2018)</a>, thus our question is a tuple of entities, where the
order defines the exact kinship relation. Finally, the task is to
classify the correct relation among 22 kinship relations.</p><h2 id=systematic-generalization>Systematic Generalization</h2><p>Systematic Generalization is the ability of a model to solve tasks on a
test distribution which is different than the training distribution,
while the test distribution has been derived from the same <em>production
rules</em> as that of the training.
<a href=https://en.wikipedia.org/wiki/Syntactic_Structures target=_blank rel=noopener>Chomsky (1957)</a>,
<a href=https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1755-2567.1970.tb00434.x target=_blank rel=noopener>Montague
(1970)</a>, <a href=https://arxiv.org/abs/1711.00350 target=_blank rel=noopener>Lake & Baroni (2018)</a>
define the term as:</p><blockquote><p>The algebraic capacity to understand and produce a potentially infinite
number of novel combinations from known components.</p></blockquote><p>This topic is <a href=https://arxiv.org/abs/1811.12889 target=_blank rel=noopener>so involved</a> it
requires a separate blog post on its own. In simple terms, we want our
NLU models to generalize on out-of-domain data distributions in a
particular task. However, restricting the scope of out-of-domain is
critical : we cannot expect a model trained on sentence entailments in
English to generalize on Bengali for instance.</p><p>In our dataset, we provide a simple way to test out-of-domain (OOD)
generalization : by evaluating on stories with different logical
compositions of the relations. To understand the composition of a single
relation, the model needs to learn all binary compositions which lead to
the particular relation. (e.g. <em>father + father = grandfather</em>, and
<em>sibling + grandfather = grandfather</em>). Once it does, the model should
be able to generalize on unseen compositions by <strong>re-using the learnt
composition functions</strong>. The test distribution is still derived from the
same <em>production rules</em>, as in the same knowledge base (KB).</p><p>OOD Generalization can be also be achieved in the level of the
underlying language in our dataset. Recall, we have used a set of
placeholders collected from AMT to construct the stories : we can thus
have a subset of the collected paraphrases being <em>held out</em> for testing.
This enables <em>linguistic generalization</em>, which explicitly restricts
models to <em>memorize</em> on syntactical artifacts of the dataset.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/sys_gen_23.png alt loading=lazy data-zoomable></div></div></figure><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/sys_gen_234.png alt loading=lazy data-zoomable></div></div></figure></p><p>We perform experiments with a combination of logical and linguistic
generalization with two types of baselines : NLU models such as BiLSTM,
Relation Networks (<a href=https://arxiv.org/abs/1706.01427 target=_blank rel=noopener>Santoro et al,
2017</a>), MAC (<a href=https://arxiv.org/abs/1803.03067 target=_blank rel=noopener>Hudson et al, 2018</a>),
and pretrained language model such as BERT
(<a href=https://arxiv.org/abs/1810.04805 target=_blank rel=noopener>Devlin et al. 2018</a>); and Graph
Attention Networks (GAT) (<a href=https://arxiv.org/abs/1710.10903 target=_blank rel=noopener>Veličković
et al, 2018</a>) working on the symbolic graphs underlying the stories. We
observe that Systematic Generalization is a hard problem with
performance decrease across all models as we increase the length of the
logical clause \(k\). This highlights the challenge of &ldquo;zero-shot&rdquo;
systematic generalization (<a href=https://arxiv.org/abs/1711.00350 target=_blank rel=noopener>Lake &
Baroni, 2018</a>; <a href=https://arxiv.org/abs/1811.07017 target=_blank rel=noopener>Sodhani et
al. 2018</a>). The performance of GAT is significantly better than all NLU
baselines, indicating that most NLU systems focus on the syntax rather
than abstract reasoning.</p><h2 id=robust-reasoning>Robust Reasoning</h2><p>The modular setup of <code>CLUTRR</code> allows us to diagnose models for
<strong>robustness</strong>, another critical form of generalization. Since all
underlying stories have a logically valid path \(G_p\), we can add
paths which are not relevant to resolution of the task. Concretely, we
can add three types of <em>noise</em>:</p><ul><li><em>Supporting facts</em>: A path which originates and ends within \(G_p\).
These are <em>extra facts</em> which are not needed to answer the query, but
can be used, in principle, to construct alternative reasoning paths.</li><li><em>Irrelevant facts</em>: A dangling path which originates from \(G_p\)
but has a different sink. This is essentially a distractor which the
model has to carefully stray away while reasoning for the given query.</li><li><em>Disconnected facts</em>: A path which neither originates nor ends in
\(G_p\). This constitute an unrelated noise in the data.</li></ul><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/ox-hugo/clutrr_noise.png alt loading=lazy data-zoomable></div></div></figure><p>Thus, we can have multiple train/test scenarios to evaluate robustness
in highly granular level by combination of the above facts with the
clean setup. We perform experiments with the same set of baselines while
fixing the length \(k\) of the clauses to \((2,3)\). We observe that
overall GAT outperforms NLU models significantly on a range of
train/test scenarios. This showcases the benefit of structure and
inductive bias for performing abstract reasoning.</p><p>We observe a couple of interesting trends as well:</p><ul><li>NLU models perform better when testing on supporting and irrelevant
facts while being trained on a noise-less setup. This suggests NLU
models actually benefit from <em>more content</em> which may provide
linguistic cues, irrelevant of the reasoning pathway.</li><li>GAT model performs poorly on the above setup which shows that it is
sensitive to changes involving cycles - it cannot understand the need
of cycles of they are not trained with one. However, GAT performs
significantly better when trained with cycles.</li></ul><h2 id=key-takeaways>Key Takeaways</h2><ul><li>We need structure / inductive biases in our models to perform better
on Generalization and Robust Reasoning</li><li>NLU models must try to represent the inductive bias or structure
internally</li><li>Systematic Generalization is hard, and we need more research in
representing compositional and modular networks.</li><li>Logic provides a provable way to devise datasets for tasks involving
abstract reasoning</li></ul><h2 id=closing-remarks>Closing Remarks</h2><p><code>CLUTRR</code> provides a fine-grained modular way to test the reasoning
capabilities of NLU systems - by asking the fundamental questions of
Systematic Generalization and Robustness. We found that existing NLU
systems perform relatively poorly on these questions compared to a
graph-based model which has symbolic inputs. This highlights the gap
that remains between machine reasoning models that work on unstructured
text and structured inputs.</p><h3 id=paper>Paper</h3><p><a href=https://arxiv.org/pdf/1908.06177.pdf target=_blank rel=noopener>Please read our paper</a> for more
information regarding dataset construction and experiments.</p><h3 id=code>Code</h3><p>Our code is available at <a href=https://github.com/facebookresearch/clutrr target=_blank rel=noopener>https://github.com/facebookresearch/clutrr</a>,
where we will be adding possible extensions and applications of the
dataset.</p><h3 id=acknowledgements>Acknowledgements</h3><p>I have a long list of people to thank for supporting this project. Will
Hamilton, Joelle Pineau (my superb advisors); Shagun Sodhani, Jin Dong
(my awesome collaborators); Jack Urbanek, Stephen Roller (for numerous
help with <a href=https://parl.ai/ target=_blank rel=noopener>ParlAI</a>); Adina Williams, Dzmitry
Bahdanau, Prasanna Parthasarathy, Harsh Satija (for discussions and
feedback); Abhishek Das, Carlos Eduardo Lassance, Gunshi Gupta, Milan
Aggarwal, Rim Assouel, Weiping Song, and Yue Dong (for feedback on the
manuscript); many anonymous Amazon Mechanical Turk participants for
providing paraphrases; Sumana Basu, Etienne Denis, Jonathan Lebensold,
and Komal Teru (for providing reviews on the dataset); Sanghyun Yoo,
Jehun Jeon and Dr Young Sang Choi of Samsung Advanced Institute of
Technology (SAIT) (for supporting the
<a href=https://arxiv.org/abs/1811.02959 target=_blank rel=noopener>workshop version</a> of the paper);
Facebook AI Research (FAIR) (for providing extensive compute resources).
This research was supported by the Canada CIFAR Chairs in AI program.</p><h3 id=citation>Citation</h3><p>If you want to use our dataset in your research, please consider citing
our paper:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl><span class=nc>@article</span><span class=p>{</span><span class=nl>sinha2019clutrr</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>Author</span> <span class=p>=</span> <span class=s>{Koustuv Sinha and Shagun Sodhani and Jin Dong and Joelle Pineau and William L. Hamilton}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>Title</span> <span class=p>=</span> <span class=s>{CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>Year</span> <span class=p>=</span> <span class=s>{2019}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>journal</span> <span class=p>=</span> <span class=s>{Empirical Methods of Natural Language Processing (EMNLP)}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>arxiv</span> <span class=p>=</span> <span class=s>{1908.06177}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>If you like the idea and want to collaborate on exciting applications,
feel free to drop me a mail at
<a href=mailto:koustuv.sinha@mail.mcgill.ca>koustuv.sinha@mail.mcgill.ca</a></p></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=/introducing-clutrr/&text=Introducing%20CLUTRR" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=/introducing-clutrr/&t=Introducing%20CLUTRR" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Introducing%20CLUTRR&body=/introducing-clutrr/" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=/introducing-clutrr/&title=Introducing%20CLUTRR" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Introducing%20CLUTRR%20/introducing-clutrr/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=/introducing-clutrr/&title=Introducing%20CLUTRR" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hucc78bc830b96374f35a67d0f4452e819_1023205_270x270_fill_q75_lanczos_center.jpg alt="Koustuv Sinha"></a><div class=media-body><h5 class=card-title><a href=/>Koustuv Sinha</a></h5><h6 class=card-subtitle>PhD Candidate</h6><p class=card-text>My research interests include natural language processing with machine learning, computational linguistics and interpretable machine learning. I organize the annual <a href=https://paperswithcode.com/rc2021 target=_blank rel=noopener>ML Reproducibility Challenge</a>.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/koustuvsinha target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=9P9QcckAAAAJ" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/koustuvsinha target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><section id=comments><script src=https://utteranc.es/client.js repo=koustuvsinha/website issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></section><div class="project-related-pages content-widget-hr"></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2022 Koustuv Sinha. This website is built using <a href=https://ox-hugo.scripter.co/ target=_blank rel=noopener>ox-hugo</a>, <a href=https://orgmode.org/ target=_blank rel=noopener>org-mode</a>, <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> and <a href=https://wowchemy.com/ target=_blank rel=noopener>Wowchemy</a>, on Emacs 28.1. Opinions expressed in this website are solely my own. While we strive for excellence in research, it is important to remember that <a href=https://www.facebook.com/nipsfoundation/videos/2120856364798049/ target=_blank rel=noopener><em>&ldquo;Science is not a competitive sport&rdquo;</em></a>.</p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.992ab4bf929c75fb2aff9ec73febac85.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>