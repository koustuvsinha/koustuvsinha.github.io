---
---

@string{aps = {American Physical Society,}}

@article{sinha2020evaluating,
  title={Evaluating Logical Generalization in Graph Neural Networks},
  author={Sinha, Koustuv and Sodhani, Shagun and Pineau, Joelle and Hamilton, William L},
  journal={arXiv preprint arXiv:2003.06560},
  arxiv = {2003.06560},
  code = {https://github.com/facebookresearch/graphlog},
  year={2020}
}

@article{pineau2020improving,
  title={Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)},
  author={Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Larivi{\`e}re, Vincent and Beygelzimer, Alina and d'Alch{\'e}-Buc, Florence and Fox, Emily and Larochelle, Hugo},
  journal={arXiv preprint arXiv:2003.12206},
  arxiv = {2003.12206},
  year={2020}
}

@article{sinha2019clutrr,
  Author = {Koustuv Sinha and Shagun Sodhani and Jin Dong and Joelle Pineau and William L. Hamilton},
  Title = {CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text},
  Year = {2019},
  journal = {Empirical Methods of Natural Language Processing (EMNLP)},
  arxiv = {1908.06177},
  abstract = {The recent success of natural language understanding (NLU) systems has been troubled by results highlighting the failure of these models to generalize in a systematic and robust way. In this work, we introduce a diagnostic benchmark suite, named CLUTRR, to clarify some key issues related to the robustness and systematicity of NLU systems. Motivated by classic work on inductive logic programming, CLUTRR requires that an NLU system infer kinship relations between characters in short stories. Successful performance on this task requires both extracting relationships between entities, as well as inferring the logical rules governing these relationships. CLUTRR allows us to precisely measure a model's ability for systematic generalization by evaluating on held-out combinations of logical rules, and it allows us to evaluate a model's robustness by adding curated noise facts. Our empirical results highlight a substantial performance gap between state-of-the-art NLU models (e.g., BERT and MAC) and a graph neural network model that works directly with symbolic inputs---with the graph-based model exhibiting both stronger generalization and greater robustness. }
}

@article{Pineau:2019,
  author = {Pineau, Joelle and Sinha, Koustuv and Fried, Genevieve and Ke, Rosemary Nan and Larochelle, Hugo},
  title = {{ICLR Reproducibility Challenge 2019}},
  journal = {ReScience C},
  year = {2019},
  month = may,
  volume = {5},
  number = {2},
  pages = {{#5}},
  doi = {10.5281/zenodo.3158244},
  url = {https://zenodo.org/record/3158244/files/article.pdf},
  code_url = {https://github.com/reproducibility-challenge/iclr_2019},
  code_doi = {},
  data_url = {},
  data_doi = {},
  review_url = {https://github.com/ReScience/submissions/issues/5},
  type = {Editorial},
  language = {},
  domain = {},
  epdf = {https://zenodo.org/record/3158244/files/article.pdf},
  keywords = {machine learning, ICLR, reproducibility challenge}
}

@article{sinha2018clutrr,
  Author = {Koustuv Sinha and Shagun Sodhani and William L. Hamilton and Joelle Pineau},
  Title = {Compositional Language Understanding with Text-based Relational Reasoning},
  Year = {2018},
  journal = {Relational Representation Learning Workshop, NIPS},
  arxiv = {1811.02959},
  code = {https://github.com/koustuvsinha/clutrr},
  abstract = {Neural networks for natural language reasoning have largely focused on extractive, fact-based question-answering (QA) and common-sense inference. However, it is also crucial to understand the extent to which neural networks can perform relational reasoning and combinatorial generalization from natural language---abilities that are often obscured by annotation artifacts and the dominance of language modeling in standard QA benchmarks. In this work, we present a novel benchmark dataset for language understanding that isolates performance on relational reasoning. We also present a neural message-passing baseline and show that this model, which incorporates a relational inductive bias, is superior at combinatorial generalization compared to a traditional recurrent neural network approach. }
}

@article{henderson2018adversarial,
  Author = {Peter Henderson and Koustuv Sinha and Rosemary Nan Ke and Joelle Pineau},
  Title = {Adversarial Gain},
  Year = {2018},
  journal = {Arxiv Pre-print},
  arxiv = {1811.01302},
  abstract = {Adversarial examples can be defined as inputs to a model which induce a mistake - where the model output is different than that of an oracle, perhaps in surprising or malicious ways. Original models of adversarial attacks are primarily studied in the context of classification and computer vision tasks. While several attacks have been proposed in natural language processing (NLP) settings, they often vary in defining the parameters of an attack and what a successful attack would look like. The goal of this work is to propose a unifying model of adversarial examples suitable for NLP tasks in both generative and classification settings. We define the notion of adversarial gain: based in control theory, it is a measure of the change in the output of a system relative to the perturbation of the input (caused by the so-called adversary) presented to the learner. This definition, as we show, can be used under different feature spaces and distance conditions to determine attack or defense effectiveness across different intuitive manifolds. This notion of adversarial gain not only provides a useful way for evaluating adversaries and defenses, but can act as a building block for future work in robustness under adversaries due to its rooted nature in stability and manifold theory. }
}

@article{gontier2018,
  Author = {Nicolas A. Gontier and Koustuv Sinha and Peter Henderson and Iulian Serban and Michael Noseworthy and Prasanna Parthasarathi and Joelle Pineau},
  Title = {The RLLChatbot: a solution to the ConvAI Challenge},
  Year = {2018},
  arxiv = {1811.02714},
  journal = {under review at Dialog & Discourse Journal (D&D)},
  abstract = {Current conversational systems can follow simple commands and answer basic questions, but they have difficulty maintaining coherent and open-ended conversations about specific topics. Competitions like the Conversational Intelligence (ConvAI) challenge are being organized to push the research development towards that goal. This article presents in detail the RLLChatbot that participated in the 2017 ConvAI challenge. The goal of this research is to better understand how current deep learning and reinforcement learning tools can be used to build a robust yet flexible open domain conversational agent. We provide a thorough description of how a dialog system can be built and trained from mostly public-domain datasets using an ensemble model. The first contribution of this work is a detailed description and analysis of different text generation models in addition to novel message ranking and selection methods. Moreover, a new open-source conversational dataset is presented. Training on this data significantly improves the Recall@k score of the ranking and selection mechanisms compared to our baseline model responsible for selecting the message returned at each interaction. }
}

@article{sinha2018hier,
  Author = {{Sinha}, Koustuv and {Dong}, Yue and {Chi-kit Cheung}, Jackie and {Ruths}, Derek},
  Title = {A Hierarchical Neural Attention-based Text Classifier},
  journal = {Empirical Methods of Natural Language Processing (EMNLP)},
  year = {2018},
  epdf = {http://www.aclweb.org/anthology/D18-1094},
  abstract = {Deep neural networks have been displaying superior  performance over traditional supervised classifiers in text classification. They learn to extract useful features automatically when sufficient amount of data is presented. However, along with the growth in the number of documents comes the increase in the number of categories, which often results in poor performance of the multiclass classifiers. In this work, we use external knowledge in the form of topic category taxonomies to aide the classification by introducing a deep hierarchical neural attention-based classifier.  Our model performs better than or comparable to state-of-the-art hierarchical models at significantly lower computational cost while maintaining high interpretability.}
}

@article{henderson2017ethics,
  Author = {{Henderson}, Peter and {Sinha}, Koustuv and {Angelard-Gontier}, Nicolas and {Ke}, {Nan Rosemary} and {Fried}, {Genevieve} and {Lowe}, Ryan and {Pineau}, Joelle},
  Title = {Ethical Challenges in Data-Driven Dialogue Systems},
  journal = {AAAI/ACM AI Ethics and Society Conference},
  year = {2018},
  arxiv = {1711.09050},
  code = {https://github.com/Breakend/EthicsInDialogue},
  abstract = {The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.}
  }
