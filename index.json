[{"authors":null,"categories":null,"content":"My current research interest involves investigating the limits of systematic language understanding of modern neural language representation systems, by leveraging linguistic and logical priors. In particular, I investigate how language is represented by neural models in a human-like way by testing their ability to understand the semantics, syntax and generalizability in the context of natural and artificial languages. I am also interested in improving the state of Generative Language Modeling (Dialog Systems).\nI’m a Research Scientist at Meta AI New York, in the Fundamental AI Research (FAIR) team. I did my PhD from McGill University (School of Computer Science) and Mila (Quebec AI Institute), supervised by Joelle Pineau, in the wonderful city of Montreal, QC, Canada. I spent a significant portion of my PhD being a Research Intern (STE) at Meta AI (FAIR), Montreal.\nI am an associate editor of ReScience C, a peer reviewed journal promoting reproducible research, and I am the lead organizer of the annual Machine Learning Reproducibility Challenge (V1, V2, V3, V4, V5 ). My work has been covered by several news outlets in the past, including Nature, VentureBeat, InfoQ, DailyMail and Hindustan Times.\nResumé | PhD Thesis ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"My current research interest involves investigating the limits of systematic language understanding of modern neural language representation systems, by leveraging linguistic and logical priors. In particular, I investigate how language is represented by neural models in a human-like way by testing their ability to understand the semantics, syntax and generalizability in the context of natural and artificial languages.","tags":null,"title":"Koustuv Sinha","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://koustuvsinha.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Koustuv Sinha","Amirhossein Kazemnejad","Siva Reddy","Joelle Pineau","Dieuwke Hupkes","Adina Williams"],"categories":[],"content":"","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671675592,"objectID":"1d519124fdaeffa5db0d5ddfb728bdbf","permalink":"https://koustuvsinha.com/publication/sinha-2022-curious/","publishdate":"2022-12-22T02:19:46.599641Z","relpermalink":"/publication/sinha-2022-curious/","section":"publication","summary":"Transformer language models encode the notion of word order using positional information. Most commonly, this positional information is represented by absolute position embeddings (APEs), that are learned from the pretraining data. However, in natural language, it is not absolute position that matters, but relative position, and the extent to which APEs can capture this type of information has not been investigated. In this work, we observe that models trained with APE over-rely on positional information to the point that they break-down when subjected to sentences with shifted position information. Specifically, when models are subjected to sentences starting from a non-zero position (excluding the effect of priming), they exhibit noticeably degraded performance on zero to full-shot tasks, across a range of model families and model sizes. Our findings raise questions about the efficacy of APEs to model the relativity of position information, and invite further introspection on the sentence and word order processing strategies employed by these models.","tags":[],"title":"The Curious Case of Absolute Position Embeddings","type":"publication"},{"authors":["McGill University, Defense Date: November 2nd, 2022, Mode: Virtual"],"categories":[],"content":" Table of Contents Thesis Committee Thesis Title Abstract Thesis Document Papers used in the Thesis Acknowledgements Pictures On November 2nd, 2022 I defended my PhD thesis successfully in front of a virtual audience. Following are the details of the thesis, committee, and a sincere acknowledgement to all of whom who have influenced, encouraged, helped and supported me throughout this epic journey!\nThesis Committee Dr. Yue Li (Chair) Dr. Joelle Pineau (Supervisor) Dr. Timothy J O’Donell (Supervisory Committee) Dr. Dima Bahdanau (Internal Member) Dr. Kyunghyun Cho (NYU) (External Member) Thesis Title “Exploring the limits of systematicity of natural language understanding models”\nAbstract In this thesis, we investigate several approaches to evaluate modern neural language models through the lens of systematicity, in order to assess their human-level reasoning and comprehension of natural language. First, we investigate the model’s limits in encoding the natural language semantics by proposing a diagnostic challenge dataset known as CLUTRR. Drawing inspiration from first-order logic, this dataset specifically tests for systematicity in length generalization in natural language understanding models, in the form of a question-answering task. We observe most major models fail in generalizing to longer chain of reasoning, with the main limitation arising from their rudimentary understanding of syntax. Next, we apply the principles of systematicity to evaluate the syntax encoding strategy of large language models by applying permutations to the word order seen during inference and training. We observe a surprising fact that a trained neural language model can still perform optimally when subjected to sentences of shuffled word orders, devoid of their original meaning, and furthermore they can even improve their performance significantly on specific permutations. Next, we investigate the reasons of such behavior by pre-training large language models on meaningless, word-order shuffled corpora, to find they too behave optimally on downstream semantic and syntactic tasks. These results highlight the potential distributional nature of large language models, such that they only focus on n-grams during computation. Finally, we attempt to investigate the root cause of these effects, to find the component of the model most responsible. We observe that certain classes of position embeddings lead the models to overfit on the token positions, subjecting models to exhibit un-systematic behavior on out-of-position sentences. In summary, this thesis attempts to shed more light to the black box nature of the state-of-the-art neural language models, and introduces mechanisms to test and ensure systematic behaviors in their understanding of natural language.\nThesis Document (To be updated post publication from McGill)\nPapers used in the Thesis Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L. Hamilton. 2019. CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4506–4515, Hong Kong, China. Association for Computational Linguistics. Koustuv Sinha, Prasanna Parthasarathi, Joelle Pineau, and Adina Williams. 2021. UnNatural Language Inference. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 7329–7346, Online. Association for Computational Linguistics. Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina Williams, and Douwe Kiela. 2021. Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2888–2913, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. Koustuv Sinha, Amirhossein Kazemnejad, Siva Reddy, Joelle Pineau, Dieuwke Hupkes, and Adina Williams, 2022. The Curious Case of Absolute Position Embeddings. In Proceedings of the Findings of 2022 Empirical Methods in Natural Language Processing, Abu Dhabi. Association of Computational Linguistics. Acknowledgements First and foremost, I would like to thank my supervisor, Joelle Pineau, for her endless support, motivation and guidance; being an incredibly patient mentor and role model for conducting scientific research; involving me in the quest to achieve reproducibility in machine learning; and continually providing me opportunities to learn and grow during my PhD. I consider myself incredibly lucky to have such a kind and enthusiastic mentor in my life.\nI would like to thank my close collaborators Adina Williams, Shagun Sodhani and Prasanna Parthasarthi for their guidance, endless support and motivation throughout many projects that are …","date":1667347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667347200,"objectID":"f68eec0d9023deb46736f92b0600848d","permalink":"https://koustuvsinha.com/phd_thesis/","publishdate":"2022-11-02T00:00:00Z","relpermalink":"/phd_thesis/","section":"","summary":"Exploring the limits of systematicity of natural language understanding models","tags":["phd-thesis"],"title":"PhD Thesis","type":"page"},{"authors":null,"categories":null,"content":"In my last blog post I described a method I use to keep track of my paper reading habits, using Emacs. Using the workflow, I can now:\nCheck the latest Arxiv papers using Elfeed Score the papers using Elfeed-Score Save the papers in a local bib file, along with pdfs, using org-ref functions Maintain a paper reading tracker document in Org Mode, where the workflow automatically adds the paper to read. One crucial step I later realised which is missing from this workflow is the ability to store papers from my browser. Typically I do not read Elfeed that religiously - my main source of papers always has been recommendations from colleagues, Twitter, conference acceptance lists etc. Thus, I need a setup where I can easily save an interesting paper I’m reading directly from the browser.\nZotero is a great bibliography management software which allows you to do exactly that. After you install Zotero, you can install Zotero-connectors for the browser you use, and once you are in any PDF/journal/conference paper page, if you click the connector it automatically saves the file in your library, and downloads the pdf accordingly. With some extra plugins (Better Bibtex, Zutilo) you can also configure your setup such that once Zotero saves the PDF, it renames the file to proper naming conventions and moves the file to your desired location. Oh, also Zotero can be configured to automatically export a bibfile of your entire library, which you can load into Emacs using your favorite bibfile search library (Helm-bibtex, Citar, Zotxt etc)!\nHowever, I have one major gripe in this workflow : this doesn’t allow me to update my paper reading org file once Zotero saves the pdf! I thought about various ways to fix this, including writing a Python file to add a watcher on my bibfile, get the latest changed bib, add a line in my org file. The problem with this approach is that Zotero updates the bibfile after formatting and sorting, so to get the last updated bib entry I need to maintain a state of history of the file. Furthermore, for any edits in the Zotero database, this watcher would run and add multiple lines of “Read paper X” in my paper reading list. There could be other easy ways to do this using Zotero, but I was out of ideas.\nPlus, this post is not about Zotero, its about doing the same functionality in Emacs using existing libraries. How do we build a connector from browser? Also, I mostly read Arxiv papers anyway, so I would not need the power of 600+ Zotero translators written for various research paper sources, just the one for Arxiv. Enter org-protocol.\nOrg-Protocol is this wonderful library which allows Emacs to intercept calls from emacsclient. I got my initial motivation to use org-protocol from this cool package: Zotra. What Zotra does is it runs the Zotero standalone translation server, where the client can send an URL of a page containing a paper/PDF and get the formatted bibtex entry as output. One caveat of Zotra is that you need to run this external program via Docker on your machine, as running the standalone with npm rarely works. Another caveat is that this translation server will return the bibtex entry without the PDF or link to PDF file in local, which is crucial for me to read the paper offline and through Helm-bibtex (checkout my last blog post). Having said that, Zotra gave me the idea to use org-protocol in the first place, for which I’m glad I stumbled into it!\nConfiguring Org-Protocol is easy. First, you need to let org-protocol know what to run when it encounters a protocol. For that, you need to add an entry to the org-protocol-protocol-alist :\n(add-to-list \u0026#39;org-protocol-protocol-alist \u0026#39;(\u0026#34;arxiv-protocol\u0026#34; :protocol \u0026#34;arxiv\u0026#34; :function arxiv-protocol)) How does org-protocol gets triggered in the first place? Open your browser and add the following bookmark (also known as bookmarklet), and name it as “Save PDF”:\njavascript:location.href=(\u0026#39;org-protocol://arxiv?url=%27+%20encodeURIComponent(location.href)).replace(/%27/gi,%22%27%22) If you click this bookmark link on any page, then it would popup a message : “Open in Emacs?”. What it does behind the scenes is that it runs a systemwide call in the org-protocol protocol, which is intercepted by emacsclient. Then, we define a sub-protocol named arxiv, which is used in the location.href bookmark, which uses a parameter url, where the current page url is encoded. Once you click OK to open the link in Emacs (set this to never ask you again in future), org-protocol now looks at the list org-protocol-protocol-alist to find whose :protocol matches the sub-protocol used in the call, and runs its corresponding :function.\nNow, all we need to do is to define a function which:\nInputs an Arxiv link (could be the PDF link or the Abstract link) Fetches the PDF and bibtex from Arxiv Stores the PDF into a predestined location, and adds the bibtex in my main bibfile Add a note about this paper to read in my paper tracker org file. We are in luck! In my last blog post, I …","date":1665613560,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665613560,"objectID":"4d378d0f420298b4dd49baa24f8b97e9","permalink":"https://koustuvsinha.com/post/emacs_org_protocol_arxiv/","publishdate":"2022-10-12T18:26:00-04:00","relpermalink":"/post/emacs_org_protocol_arxiv/","section":"post","summary":"In my last blog post I described a method I use to keep track of my paper reading habits, using Emacs. Using the workflow, I can now:\nCheck the latest Arxiv papers using Elfeed Score the papers using Elfeed-Score Save the papers in a local bib file, along with pdfs, using org-ref functions Maintain a paper reading tracker document in Org Mode, where the workflow automatically adds the paper to read.","tags":null,"title":"Replicating Zotero-connector functionality in Emacs … without Zotero!","type":"post"},{"authors":null,"categories":null,"content":"Over the last couple of years I have steadily transferred most of my workflows in Emacs (more specifically, Doom Emacs). As they truly say, Emacs is not just an editor, it is an operating system. I think Emacs is not for everyone. It has a very steep learning curve, especially with understanding a new language (elisp) for configuration. Having said that, once you learn how to use Emacs, you unlock insane levels of productivity. It is customizable beyond expectation, and allows one to “live” within Emacs for most of their daily needs. Emacs has helped me streamline my paper reading habits, which I’ll talk in detail in this post. Specifically, I use the following tools from the Emacs ecosystem: Org-Mode, Elfeed, Elfeed-score, Helm-Bibtex and Org-ref.\nDiscovering papers: Elfeed Elfeed is a very versatile RSS reader for Emacs. Turns out you can use Elfeed to subscribe to Arxiv feeds as well. Do check Chris Cundy’s post on this topic, where he introduces the concepts of Elfeed and Elfeed-score. Following the setup of Chris, I setup Elfeed to read Arxiv Atom posts in the stat.ML, cs.LG and cs.CL categories, which I typically follow anyways for new papers in NLP and ML.\nThe Basics Setting up these Atom feeds in Elfeed is trivial.\n(setq elfeed-feeds \u0026#39;(\u0026#34;http://export.arxiv.org/api/query?search_query=cat:stat.ML\u0026amp;start=0\u0026amp;max_results=100\u0026amp;sortBy=submittedDate\u0026amp;sortOrder=descending\u0026#34; \u0026#34;http://export.arxiv.org/api/query?search_query=cat:cs.LG\u0026amp;start=0\u0026amp;max_results=100\u0026amp;sortBy=submittedDate\u0026amp;sortOrder=descending\u0026#34; \u0026#34;http://export.arxiv.org/api/query?search_query=cat:cs.CL\u0026amp;start=0\u0026amp;max_results=100\u0026amp;sortBy=submittedDate\u0026amp;sortOrder=descending\u0026#34;)) The elfeed-feeds variable consists of a list of strings with the export URLs. Notice in these URL’s the max_results are set to 100, feel free to modify it if you want to fetch older entries.\nThe default Elfeed homepage is not that useful for reading arxiv papers as it truncates the titles. Chris provides a nice solution to show the title and authors list truncated by an “et. al” in the main Elfeed view.\n(defun concatenate-authors (authors-list) \u0026#34;Given AUTHORS-LIST, list of plists; return string of all authors concatenated.\u0026#34; (if (\u0026gt; (length authors-list) 1) (format \u0026#34;%s et al.\u0026#34; (plist-get (nth 0 authors-list) :name)) (plist-get (nth 0 authors-list) :name))) (defun my-search-print-fn (entry) \u0026#34;Print ENTRY to the buffer.\u0026#34; (let* ((date (elfeed-search-format-date (elfeed-entry-date entry))) (title (or (elfeed-meta entry :title) (elfeed-entry-title entry) \u0026#34;\u0026#34;)) (title-faces (elfeed-search--faces (elfeed-entry-tags entry))) (entry-authors (concatenate-authors (elfeed-meta entry :authors))) (title-width (- (window-width) 10 elfeed-search-trailing-width)) (title-column (elfeed-format-column title 100 :left)) (entry-score (elfeed-format-column (number-to-string (elfeed-score-scoring-get-score-from-entry entry)) 10 :left)) (authors-column (elfeed-format-column entry-authors 40 :left))) (insert (propertize date \u0026#39;face \u0026#39;elfeed-search-date-face) \u0026#34; \u0026#34;) (insert (propertize title-column \u0026#39;face title-faces \u0026#39;kbd-help title) \u0026#34; \u0026#34;) (insert (propertize authors-column \u0026#39;kbd-help entry-authors) \u0026#34; \u0026#34;) (insert entry-score \u0026#34; \u0026#34;))) (setq elfeed-search-print-entry-function #\u0026#39;my-search-print-fn) (setq elfeed-search-date-format \u0026#39;(\u0026#34;%y-%m-%d\u0026#34; 10 :left)) (setq elfeed-search-title-max-width 110) Then, set the default filter to show unread papers from 2 weeks ago. This is also customizable.\n(setq elfeed-search-filter \u0026#34;@2-week-ago +unread\u0026#34;) We would also like to instruct Elfeed to fetch the papers whenever we open the Elfeed interface:\n(add-hook! \u0026#39;elfeed-search-mode-hook \u0026#39;elfeed-update) Scoring papers As you may have noticed, my-search-print-fn contains the function elfeed-score-scoring-get-score-from-entry call, which uses Elfeed-score package to score individual papers. Elfeed-score is a simple but effective utility to allow you to set regex filter rules to score papers based on the relevance of your research area.\nInstall elfeed-score package using use-package, and then set the location of the rules file.\n(use-package! elfeed-score :after elfeed :config (elfeed-score-load-score-file \u0026#34;~/.doom.d/elfeed.score\u0026#34;) ; See the elfeed-score documentation for the score file syntax (elfeed-score-enable) (define-key elfeed-search-mode-map \u0026#34;=\u0026#34; elfeed-score-map)) Now go ahead and create the file elfeed.score in your location of choice. This file basically contains the rules written in elisp. For example, my rule set after a couple of days usage is this:\n;;; Elfeed score file -*- lisp -*- ((version 10) (\u0026#34;title\u0026#34; (:text \u0026#34;Transformer\u0026#34; :value 10 :type s) (:text \u0026#34;Summarization\u0026#34; :value -50 :type s)) (\u0026#34;content\u0026#34;) (\u0026#34;title-or-content\u0026#34; (:text \u0026#34;Gender Bias\u0026#34; :title-value 50 :content-value 50 :type s) (:text \u0026#34;BERT\u0026#34; :title-value 100 :content-value 50 :type S) (:text \u0026#34;Generalization\u0026#34; :title-value 30 :content-value 20 :type s) (:text \u0026#34;out-of-distribution\u0026#34; :title-value 20 :content-value 30 :type s) (:text \u0026#34;language model\u0026#34; :title-value 20 :content-value 30 :type s)) (\u0026#34;tag\u0026#34;) …","date":1658102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658102400,"objectID":"4bbd1711177b1cb72f92323450792af0","permalink":"https://koustuvsinha.com/post/emacs_research_workflow/","publishdate":"2022-07-18T00:00:00Z","relpermalink":"/post/emacs_research_workflow/","section":"post","summary":"Over the last couple of years I have steadily transferred most of my workflows in Emacs (more specifically, Doom Emacs). As they truly say, Emacs is not just an editor, it is an operating system.","tags":null,"title":"A workflow for reading, managing and discovering ML research papers with Emacs","type":"post"},{"authors":["Shanya Sharma","Manan Dey","Koustuv Sinha"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"3322c85bdbbbafe32627c8bf79ec8fe2","permalink":"https://koustuvsinha.com/publication/sharma-2022-how/","publishdate":"2022-07-18T23:57:58.726792Z","relpermalink":"/publication/sharma-2022-how/","section":"publication","summary":"Neural Machine Translation systems built on top of Transformer-based architectures are routinely improving the state-of-the-art in translation quality according to word-overlap metrics. However, a growing number of studies also highlight the inherent gender bias that these models incorporate during training, which reflects poorly in their translations. In this work, we investigate whether these models can be instructed to fix their bias during inference using targeted, guided instructions as contexts. By translating relevant contextual sentences during inference along with the input, we observe large improvements in reducing the gender bias in translations, across three popular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric to assess several large pretrained models (OPUS-MT, M2M-100) on their sensitivity towards using contexts during translation to correct their biases. Our approach requires no fine-tuning, and thus can be used easily in production systems to de-bias translations from stereotypical gender-occupation bias. We hope our method, along with our metric, can be used to build better, bias-free translation systems.","tags":["Computation and Language (cs.CL)","Machine Learning (cs.LG)","FOS: Computer and information sciences","FOS: Computer and information sciences","I.2.7","68T50"],"title":"How sensitive are translation systems to extra contexts? Mitigating gender bias in Neural Machine Translation models through relevant contexts","type":"publication"},{"authors":["Koustuv Sinha","Robin Jia","Dieuwke Hupkes","Joelle Pineau","Adina Williams","Douwe Kiela"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"7d90c0cdabb734787e47fd28d70882d8","permalink":"https://koustuvsinha.com/publication/sinha-2021-masked/","publishdate":"2022-07-18T23:57:59.485338Z","relpermalink":"/publication/sinha-2021-masked/","section":"publication","summary":"A possible explanation for the impressive performance of masked language model (MLM) pre-training is that such models have learned to represent the syntactic structures prevalent in classical NLP pipelines. In this paper, we propose a different explanation: MLMs succeed on downstream tasks almost entirely due to their ability to model higher-order word co-occurrence statistics. To demonstrate this, we pre-train MLMs on sentences with randomly shuffled word order, and show that these models still achieve high accuracy after fine-tuning on many downstream tasks -- including on tasks specifically designed to be challenging for models that ignore word order. Our models perform surprisingly well according to some parametric syntactic probes, indicating possible deficiencies in how we test representations for syntactic information. Overall, our results show that purely distributional information largely explains the success of pre-training, and underscore the importance of curating challenging evaluation datasets that require deeper linguistic knowledge.","tags":[],"title":"Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little","type":"publication"},{"authors":[],"categories":[],"content":"Abstract\nRecent investigations into the inner-workings of state-of-the-art large-scale pre-trained Transformer-based Natural Language Understanding (NLU) models indicate that they appear to understand human-like syntax, at least to some extent. We provide novel evidence that complicates this claim: we find that state-of-the-art Natural Language Inference (NLI) models assign the same labels to permuted examples as they do to the original, i.e. they are invariant to random word-order permutations. This behavior notably differs from that of humans; we struggle to understand the meaning of ungrammatical sentences. To measure the severity of this issue, we propose a suite of metrics and investigate which properties of particular permutations lead models to be word order invariant. For example, in MNLI dataset we find almost all (98.7%) examples contain at least one permutation which elicits the gold label. Models are even able to assign gold labels to permutations that they originally failed to predict correctly. We provide a comprehensive empirical evaluation of this phenomenon, and further show that this issue exists in pre-Transformer RNN / ConvNet based encoders, as well as across multiple languages (English and Chinese). Our code and data are available at https://github.com/facebookresearch/unlu.\nLatest News July 3, 2021 : We are honored to be awarded Outstanding Paper Award in ACL-IJCNLP 2021! ","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"e219a738fa20f365574f235396423acd","permalink":"https://koustuvsinha.com/project/unli/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/project/unli/","section":"project","summary":"NLU models tend to 'understand' word scrambled sentences! (ACL 2021 Long Paper)","tags":[],"title":"UnNatural Language Inference","type":"project"},{"authors":["Koustuv Sinha","Prasanna Parthasarathi","Joelle Pineau","Adina Williams"],"categories":[],"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"ff7b2d99e4454b53f3cf52958d3f777b","permalink":"https://koustuvsinha.com/publication/sinha-2021-unnat/","publishdate":"2022-07-18T23:57:59.695221Z","relpermalink":"/publication/sinha-2021-unnat/","section":"publication","summary":"Natural Language Understanding has witnessed a watershed moment with the introduction of large pre-trained Transformer networks. These models achieve state-of-the-art on various tasks, notably including Natural Language Inference (NLI). Many studies have shown that the large representation space imbibed by the models encodes some syntactic and semantic information. However, to really ``know syntax'', a model must recognize when its input violates syntactic rules and calculate inferences accordingly. In this work, we find that state-of-the-art NLI models, such as RoBERTa and BART are invariant to, and sometimes even perform better on, examples with randomly reordered words. With iterative search, we are able to construct randomized versions of NLI test sets, which contain permuted hypothesis-premise pairs with the same words as the original, yet are classified with perfect accuracy by large pre-trained models, as well as pre-Transformer state-of-the-art encoders. We find the issue to be language and model invariant, and hence investigate the root cause. To partially alleviate this effect, we propose a simple training methodology. Our findings call into question the idea that our natural language understanding models, and the tasks used for measuring their progress, genuinely require a human-like understanding of syntax. ","tags":[],"title":"UnNatural Language Inference","type":"publication"},{"authors":["Anuroop Sriram","Matthew Muckley","Koustuv Sinha","Farah Shamout","Joelle Pineau","Krzysztof J. Geras","Lea Azour","Yindalon Aphinyanaphongs","Nafissa Yakubova","William Moore"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"525a04e5d6d39f78ab56a6debd37bfb4","permalink":"https://koustuvsinha.com/publication/sriram-2021-covid-19/","publishdate":"2022-07-18T23:57:59.881715Z","relpermalink":"/publication/sriram-2021-covid-19/","section":"publication","summary":"The rapid spread of COVID-19 cases in recent months has strained hospital resources, making rapid and accurate triage of patients presenting to emergency departments a necessity. Machine learning techniques using clinical data such as chest X-rays have been used to predict which patients are most at risk of deterioration. We consider the task of predicting two types of patient deterioration based on chest X-rays: adverse event deterioration (i.e., transfer to the intensive care unit, intubation, or mortality) and increased oxygen requirements beyond 6 L per day. Due to the relative scarcity of COVID-19 patient data, existing solutions leverage supervised pretraining on related non-COVID images, but this is limited by the differences between the pretraining data and the target COVID-19 patient data. In this paper, we use self-supervised learning based on the momentum contrast (MoCo) method in the pretraining phase to learn more general image representations to use for downstream tasks. We present three results. The first is deterioration prediction from a single image, where our model achieves an area under receiver operating characteristic curve (AUC) of 0.742 for predicting an adverse event within 96 hours (compared to 0.703 with supervised pretraining) and an AUC of 0.765 for predicting oxygen requirements greater than 6 L a day at 24 hours (compared to 0.749 with supervised pretraining). We then propose a new transformer-based architecture that can process sequences of multiple images for prediction and show that this model can achieve an improved AUC of 0.786 for predicting an adverse event at 96 hours and an AUC of 0.848 for predicting mortalities at 96 hours. A small pilot clinical study suggested that the prediction accuracy of our model is comparable to that of experienced radiologists analyzing the same information.","tags":[],"title":"COVID-19 Deterioration Prediction via Self-Supervised Representation Learning and Multi-Image Prediction","type":"publication"},{"authors":["Shanya Sharma","Manan Dey","Koustuv Sinha"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"627d658679c9ae33e7dc3c48bacb48ad","permalink":"https://koustuvsinha.com/publication/sharma-2021-evaluating/","publishdate":"2022-07-18T23:57:58.627677Z","relpermalink":"/publication/sharma-2021-evaluating/","section":"publication","summary":"Gender-bias stereotypes have recently raised significant ethical concerns in natural language processing. However, progress in the detection and evaluation of gender-bias in natural language understanding through inference is limited and requires further investigation. In this work, we propose an evaluation methodology to measure these biases by constructing a probe task that involves pairing a gender-neutral premise against a gender-specific hypothesis. We use our probe task to investigate state-of-the-art NLI models on the presence of gender stereotypes using occupations. Our findings suggest that three models (BERT, RoBERTa, and BART) trained on MNLI and SNLI data-sets are significantly prone to gender-induced prediction errors. We also find that debiasing techniques such as augmenting the training dataset to ensure that it is a gender-balanced dataset can help reduce such bias in certain cases.","tags":[],"title":"Evaluating Gender Bias in Natural Language Inference ","type":"publication"},{"authors":["Prasanna Parthasarathi","Koustuv Sinha","Joelle Pineau","Adina Williams"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"b551f88e138dbdddfe7935bb8834dd6b","permalink":"https://koustuvsinha.com/publication/parthasarathi-2021-want/","publishdate":"2022-07-18T23:57:58.454585Z","relpermalink":"/publication/parthasarathi-2021-want/","section":"publication","summary":"Rapid progress in Neural Machine Translation (NMT) systems over the last few years has been driven primarily towards improving translation quality, and as a secondary focus, improved robustness to input perturbations (e.g. spelling and grammatical mistakes). While performance and robustness are important objectives, by over-focusing on these, we risk overlooking other important properties. In this paper, we draw attention to the fact that for some applications, faithfulness to the original (input) text is important to preserve, even if it means introducing unusual language patterns in the (output) translation. We propose a simple, novel way to quantify whether an NMT system exhibits robustness and faithfulness, focusing on the case of word-order perturbations. We explore a suite of functions to perturb the word order of source sentences without deleting or injecting tokens, and measure the effects on the target side in terms of both robustness and faithfulness. Across several experimental conditions, we observe a strong tendency towards robustness rather than faithfulness. These results allow us to better understand the trade-off between faithfulness and robustness in NMT, and opens up the possibility of developing systems where users have more autonomy and control in selecting which property is best suited for their use case. ","tags":[],"title":"Sometimes We Want Ungrammatical Translations","type":"publication"},{"authors":["Koustuv Sinha","Jessica Zosa Forde"],"categories":null,"content":"A recurrent challenge in machine learning research is to ensure that the presented and published results are reliable, robust, and reproducible [4,5,6,7].\nReproducibility, obtaining similar results as presented in a paper using the same code and data, is necessary to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors.\nIn this blog post, we will share commonly used tools and explain 12 basic practices that you can use in your research to ensure reproducible science.\nTools Updated : 21st December, 2020\nPractice Tools 1 Config Management Hydra, OmegaConf, Pytorch Lightning 2 Checkpoint Management Pytorch Lightning, TestTube 3 Logging Tensorboard, Comet.ML, Weights \u0026amp; Biases, MLFlow, Visdom, Neptune 4 Seed Check best practices below - Experiment Management Pytorch Lightning, MLFlow, Determined.AI 5 Versioning Github, Gitlab, Replicate.AI 6 Data Management DVC, CML, Replicate.AI 7 Data analysis Jupyter Notebook, papermill, JupyterLab, Google Colab 8 Reporting Matplotlib, Seaborn , Pandas, Overleaf 9 Dependency Management pip, conda, Poetry, Docker, Singularity, repo2docker 10 Open Source Release Squash Commits, Binder 11 Effective Communication ML Code Completeness Checklist, ML Reproducibility Checklist 12 Test and Validate AWS, GCP, CodeOcean Practices 1. Config Management When you begin implementing your research code, the first line of work is to define an argument parser to define the set of parameters your code expects. These set of hyperparameters can typically look like this:\npython train.py --hidden_dim 100 --batch_size 32 --num_tasks 10 --dropout 0.2 --with_mask --log_interval 100 --learning_rate 0.001 --optimizer sgd --scheduler plateau --scheduler_gamma 0.9 --weight_decay 0.9 These sets of arguments typically grow over time in your research project, making maintenance and reproducibility a pain. Typically in your code, you should be careful to log all hyperparameters for all experiments, so that you can replicate an old version of your code. Pytorch Lightning provides a great way to log all hyperparameters in .csv files in the experiment output folder, allowing for better reproducibility.\nAn alternative to using a long list of argparse elements is to use config files. Config files can be either in JSON or YAML format (I prefer YAML due to the ability to add comments), where you can set your hyperparams in a logically nested way. The above set of hyperparams could be organized as:\n# config.yaml general: # for generic args batch_size: 32 num_tasks: 10 with_mask: False log_interval: 100 optim: # for optimizer args learning_rate: 0.001 optimizer: sgd scheduler: plateau scheduler_gamma: 0.9 weight_decay: 0.9 model: hidden_dim: 100 OmegaConf (part of Hydra) is a great library that allows you to maintain these config files while providing added flexibility to import previous config files and modify only a few values.\n2. Checkpoint Management Managing your model checkpoints is very important in terms of reproducibility, as it allows you to release trained models for the community to easily verify your work, as well as build upon it. Ideally, you should save your checkpoints as frequently as possible. Given the system resource restrictions, it is usually not feasible. Thus, it is ideal to save the last checkpoint along with the checkpoint of the last best model (according to your evaluation metrics). Pytorch Lightning provides an in-built solution to do this efficiently.\n3. Logging When training your model, you realize that for several parameters it is not giving you the ideal performance. Ideally, you want to check several things. Is the training loss of the model saturating? Is it still going down? How is the validation performance over training look like? You need to log all the metrics efficiently, and later plot those metrics in nice shiny plots for analysis and inspection.\nLogging is also important for reproducibility, so researchers can verify the training progression of their replications in great detail.\nIn the bare-bones setup, you could just log all metrics in the filesystem and then plot by loading them in a python script using matplotlib. To make this process easy and also to provide live, interactive plots, several services are available now which you can leverage in your work. Tensorboard, for example, is popular in the ML community primarily for its early adoption and ability to deploy locally. Newer entrants, like Comet.ML, WandB or MLFlow, provide exciting features ranging from sharable online logging interfaces, with fine-grained ability to monitor experiments and hyperparams. In a future blog post, we will discuss on the pros and cons of these systems.\n4. Setting the seed Probably the most …","date":1596585600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596585600,"objectID":"030cc810f244398b11ac834b8ae7cb3f","permalink":"https://koustuvsinha.com/practices_for_reproducibility/","publishdate":"2020-08-05T00:00:00Z","relpermalink":"/practices_for_reproducibility/","section":"post","summary":"A recurrent challenge in machine learning research is to ensure that the presented and published results are reliable, robust, and reproducible [4,5,6,7].\nReproducibility, obtaining similar results as presented in a paper using the same code and data, is necessary to verify the reliability of research findings.","tags":null,"title":"ML Reproducibility Tools and Best Practices","type":"post"},{"authors":[],"categories":[],"content":"Koustuv Sinha, Shagun Sodhani, Joelle Pineau, William L. Hamilton\nAbstract\nRecent research has highlighted the role of relational inductive biases in building learning agents that can generalize and reason in a compositional manner. However, while relational learning algorithms such as graph neural networks (GNNs) show promise, we do not understand how effectively these approaches can adapt to new tasks. In this work, we study the task of logical generalization using GNNs by designing a benchmark suite grounded in first-order logic. Our benchmark suite, GraphLog, requires that learning algorithms perform rule induction in different synthetic logics, represented as knowledge graphs. GraphLog consists of relation prediction tasks on 57 distinct logical domains. We use GraphLog to evaluate GNNs in three different setups: single-task supervised learning, multi-task pretraining, and continual learning. Unlike previous benchmarks, our approach allows us to precisely control the logical relationship between the different tasks. We find that the ability for models to generalize and adapt is strongly determined by the diversity of the logical rules they encounter during training, and our results highlight new challenges for the design of GNN models.\nLatest News May 24, 2020 : Code for experiments in the paper released in GraphLog repository April 25, 2020 : Added simple supervised experiments using GraphLog in Pytorch Lightning ","date":159624e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":159624e4,"objectID":"a9c199c80ef91760dee8ba0642652146","permalink":"https://koustuvsinha.com/project/graphlog/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/project/graphlog/","section":"project","summary":"GraphLog is a multi-purpose, multi-relational graph dataset built using rules grounded in first-order logic.","tags":[],"title":"GraphLog","type":"project"},{"authors":["Koustuv Sinha","Joelle Pineau","Jessica Forde","Rosemary Nan Ke","Hugo Larochelle"],"categories":[],"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"42a55dd5285c6a1ec1cc3ec70dc0a117","permalink":"https://koustuvsinha.com/publication/sinha-2020-neurips/","publishdate":"2022-07-18T23:57:59.253118Z","relpermalink":"/publication/sinha-2020-neurips/","section":"publication","summary":"","tags":[],"title":"NeurIPS 2019 Reproducibility Challenge","type":"publication"},{"authors":null,"categories":null,"content":"GraphLog - Suite of 57 graph worlds built using first-order logic\nKoustuv Sinha, Shagun Sodhani, Joelle Pineau and William L. Hamilton\nCode | Docs | Paper | Home Page | Teaser Talk\nMotivation A question that we are highly interested in finding an answer to is how generalizable our learning algorithms are? Human beings are incredibly good at generalization - even at old age, we can learn new concepts and apply them in practice. Critical steps towards building algorithms that think like human beings include Multitask Learning - the ability to learn multiple concepts at once; and Continual Learning - the ability to accumulate new knowledge without forgetting the previous knowledge.\nDefining a task that aims at either Multitask Learning or Continual learning is challenging - the task should accurately quantify the “distribution shift” in the data. Having precise control of this shift could allow us to understand the drawbacks of our learning methods, and build systems which can generalize over multiple tasks but still remember the old ones.\nData distributions can be quantified by generating them based on a grammar. First-order logic, even with its basic use-case and restrictions, can be an excellent tool for defining such generalizable distributions - to test how systematic a model is. In our prior work, we leveraged first-order logic to build the CLUTRR dataset, which provides a kinship-relation game in natural language QA setting. A nice property of CLUTRR is that it is designed to be a dynamic dataset - one can always roll out longer kinship relation trees to stress-test the generalizability of their proposed approach. Since it is designed to be diagnostic, it opens up the possibility of investigating the semantic understanding capability of Natural Language Understanding models under microscopic precision.\nWhile CLUTRR primarily investigates the aspect of length generalization, the core semantic rules driving the kinship relations are static. In a real-world scenario, a model may have to adapt to the change in underlying dynamics of the domain (for example, recommender systems trained on one domain being deployed / finetuned on a new domain). In terms of grammar, two domains sharing the same grammar constitute similar domains. We need a task where we can generalize over different grammars and control the amount of distribution shift.\nIntroducing GraphLog In this work, we introduce a new paradigm of testing domain generalization in graph-structure data, named GraphLog. Instead of being a single dataset, GraphLog v1.0 contains 57 datasets, which have their own set of grammar or generation rules.\nThe Task : We are primarily interested in relation prediction, where given a graph \\(g_i\\), a source node \\(v_i\\), and sink node \\(v_j\\), the task is to predict the type of the edge \\(r\\) between \\((v_i, v_j)\\). In Graph Neural Network (GNN) world, this task is typically performed by RGCN model on popular relation prediction datasets.\nGraphs in GraphLog are generated using rules in first-order logic. These rules are 2-ary Horn clauses in the form of \\([r_i, r_j] \\rightarrow r_j\\), where \\(r_i\\) are the types of relation. Each world is a dataset on its own, which consists of 5000 graphs procedurally generated by their own set of rules, which themselves are generated stochastically. Between multiple worlds, there can be overlap between the rules, which helps us in explicitly quantifying the shift in the data distribution. This enables us to perform Multi-task learning and Continual learning along with supervised learning experiments in graph-structured data, which is one of the first datasets which propose to do so.\nDataset Inspectable Rules Diversity Compositional Generalization Modality S Me Mu CL CLEVR ✅ ❌ ❌ Vision ✅ ❌ ❌ ❌ Cogent ✅ ❌ ✅ Vision ✅ ❌ ❌ ❌ CLUTRR ✅ ❌ ✅ Text ✅ ❌ ❌ ❌ SCAN ✅ ❌ ✅ Text ✅ ✅ ❌ ❌ SQoOP ✅ ❌ ✅ Vision ✅ ❌ ❌ ❌ TextWorld ❌ ✅ ✅ Text ✅ ✅ ✅ ✅ GraphLog ✅ ✅ ✅ Graph ✅ ✅ ✅ ✅ Supervised Learning GraphLog can be used to perform supervised relation prediction tasks in any of its multiple worlds. Due to the stochastic nature of rule generation, certain worlds are more difficult than others. We define the notion of difficulty empirically based on model performance, but we observe a correlation with the number of descriptors or unique walks in the graphs associated with a world.\nMulti-task Learning GraphLog makes it easy to extend the supervised learning framework for multi-task learning by transferring model parameters on the next task. We find the model’s capacity saturates at 20 tasks, however we hypothesize larger capacity with more data points will increase the number of tasks. We use a two-step model that adapts for relations in different worlds, the details of which can be found in our paper.\nContinual Learning GraphLog enables us to evaluate the generalization capability of graph neural networks in the sequential continual learning setup where the model is trained on a sequence of worlds. Before training on …","date":1587772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587772800,"objectID":"466d66ac7098fb10c2bb5dafc24b65a8","permalink":"https://koustuvsinha.com/about-graphlog/","publishdate":"2020-04-25T00:00:00Z","relpermalink":"/about-graphlog/","section":"post","summary":"GraphLog - Suite of 57 graph worlds built using first-order logic\nKoustuv Sinha, Shagun Sodhani, Joelle Pineau and William L. Hamilton\nCode | Docs | Paper | Home Page | Teaser Talk","tags":null,"title":"GraphLog","type":"post"},{"authors":["Koustuv Sinha","Shagun Sodhani","Joelle Pineau","William L Hamilton"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"b6eb521d342900e1ed6b2efc34b2549f","permalink":"https://koustuvsinha.com/publication/sinha-2020-evaluating/","publishdate":"2022-07-18T23:57:59.058866Z","relpermalink":"/publication/sinha-2020-evaluating/","section":"publication","summary":"Recent research has highlighted the role of relational inductive biases in building learning agents that can generalize and reason in a compositional manner. However, while relational learning algorithms such as graph neural networks (GNNs) show promise, we do not understand how effectively these approaches can adapt to new tasks. In this work, we study the task of logical generalization using GNNs by designing a benchmark suite grounded in first-order logic. Our benchmark suite, GraphLog, requires that learning algorithms perform rule induction in different synthetic logics, represented as knowledge graphs. GraphLog consists of relation prediction tasks on 57 distinct logical domains. We use GraphLog to evaluate GNNs in three different setups: single-task supervised learning, multi-task pretraining, and continual learning. Unlike previous benchmarks, our approach allows us to precisely control the logical relationship between the different tasks. We find that the ability for models to generalize and adapt is strongly determined by the diversity of the logical rules they encounter during training, and our results highlight new challenges for the design of GNN models.","tags":[],"title":"Evaluating Logical Generalization in Graph Neural Networks","type":"publication"},{"authors":["Shagun Sodhani","Mayoore S Jaiswal","Lauren Baker","Koustuv Sinha","Carl Shneider","Peter Henderson","Joel Lehman","Ryan Lowe"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"b8398af35928bcdc56c629ed43557d28","permalink":"https://koustuvsinha.com/publication/sodhani-2020-ideas/","publishdate":"2022-07-18T23:57:59.801004Z","relpermalink":"/publication/sodhani-2020-ideas/","section":"publication","summary":"This report documents ideas for improving the field of machine learning, which arose from discussions at the ML Retrospectives workshop at NeurIPS 2019. The goal of the report is to disseminate these ideas more broadly, and in turn encourage continuing discussion about how the field could improve along these axes. We focus on topics that were most discussed at the workshop: incentives for encouraging alternate forms of scholarship, re-structuring the review process, participation from academia and industry, and how we might better train computer scientists as scientists.","tags":[],"title":"Ideas for Improving the Field of Machine Learning: Summarizing Discussion from the NeurIPS 2019 Retrospectives Workshop","type":"publication"},{"authors":["Joelle Pineau","Philippe Vincent-Lamarre","Koustuv Sinha","Vincent Larivière","Alina Beygelzimer","Florence d'Alché-Buc","Emily Fox","Hugo Larochelle"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"2ef97bf965efe60882c93aad8eae2ec5","permalink":"https://koustuvsinha.com/publication/pineau-2020-improving/","publishdate":"2022-07-18T23:57:58.532714Z","relpermalink":"/publication/pineau-2020-improving/","section":"publication","summary":"One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.","tags":[],"title":"Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)","type":"publication"},{"authors":["Koustuv Sinha","Prasanna Parthasarathi","Jasmine Wang","Ryan Lowe","William L. Hamilton","Joelle Pineau"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"1285cda571a73fb89a87e5afe3d86fce","permalink":"https://koustuvsinha.com/publication/sinha-2020-maude/","publishdate":"2022-07-18T23:57:59.165481Z","relpermalink":"/publication/sinha-2020-maude/","section":"publication","summary":"Evaluating the quality of a dialogue interaction between two agents is a difficult task, especially in open-domain chit-chat style dialogue. There have been recent efforts to develop automatic dialogue evaluation metrics, but most of them do not generalize to unseen datasets and/or need a human-generated reference response during inference, making it infeasible for online evaluation. Here, we propose an unreferenced automated evaluation metric that uses large pre-trained language models to extract latent representations of utterances, and leverages the temporal transitions that exist between them. We show that our model achieves higher correlation with human annotations in an online setting, while not requiring true responses for comparison during inference.","tags":[],"title":"Learning an Unreferenced Metric for Online Dialogue Evaluation","type":"publication"},{"authors":["Nicolas Gontier","Koustuv Sinha","Siva Reddy","Christopher Pal"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"3e9e986cb47281e26ee222e9024a0414","permalink":"https://koustuvsinha.com/publication/gontier-2020-measuring/","publishdate":"2022-07-18T23:57:58.009984Z","relpermalink":"/publication/gontier-2020-measuring/","section":"publication","summary":"We are interested in understanding how well Transformer language models (TLMs) can perform reasoning tasks when trained on knowledge encoded in the form of natural language. We investigate systematic generalization abilities on an inductive logical reasoning task in natural language, which involves reasoning over relationships between entities grounded in first-order logical proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to generate logical proofs represented in natural language. We systematically test proof generation capabilities, along with inference capabilities leveraging the generated proofs. We observe length-generalization issues in proof generation and inference when evaluated on longer-than-trained sequences. However, we observe TLMs improve their generalization performance after being exposed to longer, exhaustive proofs. In addition, we discover that TLMs are able to generalize better using backward-chaining proofs compared to their forward-chaining counterparts, while they find it easier to generate forward chaining proofs. We observe that models that are not trained to generate proofs are better at generalizing to problems based on longer proofs. This result suggests that Transformers have efficient, yet not interpretable reasoning strategies internally. These results also highlight the systematic generalization issues in TLMs in the context of logical reasoning, and we believe this work will motivate deeper inspection of their underlying reasoning strategies. ","tags":[],"title":"Measuring Systematic Generalization in Neural Proof Generation with Transformers","type":"publication"},{"authors":["Emily Goodwin","Koustuv Sinha","Timothy J. O'Donnell"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"2c1734f1d6f0d0adddde844bc71ff0c2","permalink":"https://koustuvsinha.com/publication/goodwin-2020-probing/","publishdate":"2022-07-18T23:57:58.089808Z","relpermalink":"/publication/goodwin-2020-probing/","section":"publication","summary":"Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicity; generalizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic. ","tags":[],"title":"Probing Linguistic Systematicity","type":"publication"},{"authors":[],"categories":[],"content":"A Diagnostic Benchmark for Inductive Reasoning from Text.\nKoustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L. Hamilton\nAbstract The recent success of natural language understanding (NLU) systems has been troubled by results highlighting the failure of these models to generalize in a systematic and robust way. In this work, we introduce a diagnostic benchmark suite, named CLUTRR, to clarify some key issues related to the robustness and systematicity of NLU systems. Motivated by classic work on inductive logic programming, CLUTRR requires that an NLU system infer kinship relations between characters in short stories. Successful performance on this task requires both extracting relationships between entities, as well as inferring the logical rules governing these relationships. CLUTRR allows us to precisely measure a model’s ability for systematic generalization by evaluating on held-out combinations of logical rules, and it allows us to evaluate a model’s robustness by adding curated noise facts. Our empirical results highlight a substantial performance gap between state-of-the-art NLU models (e.g., BERT and MAC) and a graph neural network model that works directly with symbolic inputs—with the graph-based model exhibiting both stronger generalization and greater robustness.\n","date":1567814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567814400,"objectID":"6a8755c3ec5145613ae652ab000b6eda","permalink":"https://koustuvsinha.com/project/clutrr/","publishdate":"2019-09-07T00:00:00Z","relpermalink":"/project/clutrr/","section":"project","summary":"A Diagnostic Benchmark for Inductive Reasoning from Text","tags":[],"title":"CLUTRR","type":"project"},{"authors":null,"categories":null,"content":"Compositional Language Understanding with Text based Relational Reasoning\nMotivation Question Answering (QA) has recently gained popularity as the major domain of testing reasoning in text. The literature thus contains a deluge of Question Answering (QA) datasets to choose from. These datasets test the system’s ability to extract factual answers from the text. However, there are growing concerns regarding the ability of Natural Language Understanding (NLU) models to generalize - both in a systematic and robust way. Adding to that, the recent dominance of large pre-trained language models (such as BERT, Devlin et al. 2018) on many NLU benchmarks including QA suggests that the primary difficulty in these datasets are about incorporating the statistics of the language, or the syntax of the language, rather than pure reasoning.\nWe want to develop systems which perform reasoning inductively, i.e. not only by pure extraction of text facts but by performing a higher-order reasoning and drawing conclusions based on evidence. Ideally, we also want the systems to generalize on unseen distributions, as well as be robust to adversarial attacks. To facilitate that research, we present our diagnostic suite “CLUTRR”.\nOverview Our benchmark suite CLUTRR contains a large set of semi-synthetic stories involving hypothetical families. Given a story, the goal is to infer the relationship between two family members, whose relationship is not explicitly mentioned.\nTo solve this task, an agent must extract the logical rules governing the composition of the relationships (e.g. the transitivity of the sibling relations). The benchmark allows us to test the learning agent’s ability for systematic generalization by testing on stories that contain unseen combinations of logical rules. It also allows us to precisely test for the various forms of model robustness by adding different kinds of superfluous noise facts to the stories.\nDataset Construction To derive a dataset which provides an effective way to test generalization and robustness, we looked into classical Logic. Inductive Logic Programming (ILP) is a vast field of work which tries to solve the exact problem of inductively inferring rules from a given set of data, and one of the classical examples in the field is deducing kinship relations. For example, given the facts:\n“Alice is Bob’s mother” “Jim is Alice’s father” one can infer with reasonable certainty that:\n“Jim is Bob’s grandfather” While this may appear trivial to us, it is a challenging task to design models that can learn from the data to induce the logical rules necessary to make such inferences. For the above example, the system needs to learn the rule:\n\\[ [\\texttt{grandfatherOf},X,Y] \\vdash [[\\texttt{fatherOf},X,Z], [\\texttt{fatherOf}, Z,Y]] \\]\nIn ILP, a subset of the above rules was provided as background knowledge to the system. The system then used to generate higher-order of rules by recombining existing rules and validating it with the given data.\nInspired by this classic task, we set upon building a QA task where each story is grounded with a logical rule. The core idea being that each story would describe a set of natural language relations, and the target is to infer the relationship between two entities whose relationship is not explicitly stated in the story.\nTo generate such a story, we first design a knowledge base (KB) of valid relation compositions for the kinship world. In practice, we used a set of 15 simple rules by carefully avoiding possible ambiguities (such as relations derived from in-laws). Using these set of rules, we generate the underlying kinship graph, i.e. a graph containing the kinship relations about a toy family.\nFrom this kinship graph, we sample an edge which becomes our target relation to predict. Recall, since we used logical rules to derive this graph, a path or walk in the graph from a source to sink constitutes a valid logical rule or clause. We simply sample such a path of length \\(k\\), where \\(k\\) is the tunable parameter for the data generation.\nAdding Language Given this sampled path \\(G_p\\), we aim to convert this into semi-synthetic text. The naive way would be to just replace each edge in the path by a placeholder text explaining the relationship between them. Consider the example provided in the above figure. The path \\[ B \\rightarrow A \\rightarrow D \\rightarrow G \\] can be replaced by the following text:\n\\[ B \\rightarrow A \\] : B is the wife of A \\[ A \\rightarrow D \\] : D is the daughter of A \\[ D \\rightarrow G \\] : D is the mother of G However, as you can see it already, this ends up to a very artificial dataset having less linguistic variation. Thus, to reduce the artificial flavor, we asked Amazon Mechanical Turkers to provide us paraphrases for entire sampled paths. The above example then converts to:\nA went to shopping with her wife B at the local grocery store. His daughter, D, is visiting them for thanksgiving with her daughter G.\nThis adds extra levels of …","date":1567814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567814400,"objectID":"66874b7ef3bc8ad03258e3919212dec2","permalink":"https://koustuvsinha.com/introducing-clutrr/","publishdate":"2019-09-07T00:00:00Z","relpermalink":"/introducing-clutrr/","section":"post","summary":"Compositional Language Understanding with Text based Relational Reasoning\nMotivation Question Answering (QA) has recently gained popularity as the major domain of testing reasoning in text. The literature thus contains a deluge of Question Answering (QA) datasets to choose from.","tags":null,"title":"Introducing CLUTRR","type":"post"},{"authors":["Joelle Pineau","Koustuv Sinha","Genevieve Fried","Rosemary Nan Ke","Hugo Larochelle"],"categories":[],"content":"","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188677,"objectID":"d175232c59c64c981222823a6f955a3a","permalink":"https://koustuvsinha.com/publication/pineau-2019/","publishdate":"2022-07-18T23:57:57.722376Z","relpermalink":"/publication/pineau-2019/","section":"publication","summary":"","tags":["machine learning","ICLR","reproducibility challenge"],"title":"ICLR Reproducibility Challenge 2019","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://koustuvsinha.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Koustuv Sinha","Shagun Sodhani","Jin Dong","Joelle Pineau","William L. Hamilton"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188679,"objectID":"91ae7945c78177ac99612186a7c75b0e","permalink":"https://koustuvsinha.com/publication/sinha-2019-clutrr/","publishdate":"2022-07-18T23:57:58.973811Z","relpermalink":"/publication/sinha-2019-clutrr/","section":"publication","summary":"The recent success of natural language understanding (NLU) systems has been troubled by results highlighting the failure of these models to generalize in a systematic and robust way. In this work, we introduce a diagnostic benchmark suite, named CLUTRR, to clarify some key issues related to the robustness and systematicity of NLU systems. Motivated by classic work on inductive logic programming, CLUTRR requires that an NLU system infer kinship relations between characters in short stories. Successful performance on this task requires both extracting relationships between entities, as well as inferring the logical rules governing these relationships. CLUTRR allows us to precisely measure a model's ability for systematic generalization by evaluating on held-out combinations of logical rules, and it allows us to evaluate a model's robustness by adding curated noise facts. Our empirical results highlight a substantial performance gap between state-of-the-art NLU models (e.g., BERT and MAC) and a graph neural network model that works directly with symbolic inputs---with the graph-based model exhibiting both stronger generalization and greater robustness. ","tags":[],"title":"CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text","type":"publication"},{"authors":[],"categories":[],"content":"Minimalist connect-the-dots environment for RL agents!\nTurtle Learning Environment (TLE) is a minimalistic connect-the-dots environment made as part of COMP 767 RL Final project in McGill University (Winter 2018). The objective of the agent in a 28x28 grid world is to connect the dots provided to form the image, where the environment provides negative reward for each cell drawn and positive reward for each connected components.\n","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"d90e085304cf7ff32b63a64bd47c261b","permalink":"https://koustuvsinha.com/project/tle/","publishdate":"2018-08-01T00:00:00Z","relpermalink":"/project/tle/","section":"project","summary":"Minimalist connect-the-dots environment for RL agents!","tags":[],"title":"Turtle Learning Environment (TLE)","type":"project"},{"authors":["Koustuv Sinha","Yue Dong","Jackie Chi-kit Cheung","Derek Ruths"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"1c349f625d2c8451c54e04722ceec8cd","permalink":"https://koustuvsinha.com/publication/sinha-2018-hier/","publishdate":"2022-07-18T23:57:58.88406Z","relpermalink":"/publication/sinha-2018-hier/","section":"publication","summary":"Deep neural networks have been displaying superior performance over traditional supervised classifiers in text classification. They learn to extract useful features automatically when sufficient amount of data is presented. However, along with the growth in the number of documents comes the increase in the number of categories, which often results in poor performance of the multiclass classifiers. In this work, we use external knowledge in the form of topic category taxonomies to aide the classification by introducing a deep hierarchical neural attention-based classifier. Our model performs better than or comparable to state-of-the-art hierarchical models at significantly lower computational cost while maintaining high interpretability.","tags":[],"title":"A Hierarchical Neural Attention-based Text Classifier","type":"publication"},{"authors":["Peter Henderson","Koustuv Sinha","Rosemary Nan Ke","Joelle Pineau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"af2220ea2dff368d788506fe6489e8d5","permalink":"https://koustuvsinha.com/publication/henderson-2018-adversarial/","publishdate":"2022-07-18T23:57:58.371604Z","relpermalink":"/publication/henderson-2018-adversarial/","section":"publication","summary":"Adversarial examples can be defined as inputs to a model which induce a mistake - where the model output is different than that of an oracle, perhaps in surprising or malicious ways. Original models of adversarial attacks are primarily studied in the context of classification and computer vision tasks. While several attacks have been proposed in natural language processing (NLP) settings, they often vary in defining the parameters of an attack and what a successful attack would look like. The goal of this work is to propose a unifying model of adversarial examples suitable for NLP tasks in both generative and classification settings. We define the notion of adversarial gain: based in control theory, it is a measure of the change in the output of a system relative to the perturbation of the input (caused by the so-called adversary) presented to the learner. This definition, as we show, can be used under different feature spaces and distance conditions to determine attack or defense effectiveness across different intuitive manifolds. This notion of adversarial gain not only provides a useful way for evaluating adversaries and defenses, but can act as a building block for future work in robustness under adversaries due to its rooted nature in stability and manifold theory. ","tags":[],"title":"Adversarial Gain","type":"publication"},{"authors":["Koustuv Sinha","Shagun Sodhani","William L. Hamilton","Joelle Pineau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"a1380737f844d958141c2cd2e6d5fecd","permalink":"https://koustuvsinha.com/publication/sinha-2018-clutrr/","publishdate":"2022-07-18T23:57:58.806035Z","relpermalink":"/publication/sinha-2018-clutrr/","section":"publication","summary":"Neural networks for natural language reasoning have largely focused on extractive, fact-based question-answering (QA) and common-sense inference. However, it is also crucial to understand the extent to which neural networks can perform relational reasoning and combinatorial generalization from natural language---abilities that are often obscured by annotation artifacts and the dominance of language modeling in standard QA benchmarks. In this work, we present a novel benchmark dataset for language understanding that isolates performance on relational reasoning. We also present a neural message-passing baseline and show that this model, which incorporates a relational inductive bias, is superior at combinatorial generalization compared to a traditional recurrent neural network approach. ","tags":[],"title":"Compositional Language Understanding with Text-based Relational Reasoning","type":"publication"},{"authors":["Peter Henderson","Koustuv Sinha","Nicolas Angelard-Gontier","Nan Rosemary Ke","Genevieve Fried","Ryan Lowe","Joelle Pineau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"99d98c32e7ee77e90d240302ba7f0bf5","permalink":"https://koustuvsinha.com/publication/henderson-2017-ethics/","publishdate":"2022-07-18T23:57:58.286273Z","relpermalink":"/publication/henderson-2017-ethics/","section":"publication","summary":"The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.","tags":[],"title":"Ethical Challenges in Data-Driven Dialogue Systems","type":"publication"},{"authors":["Nicolas A. Gontier","Koustuv Sinha","Peter Henderson","Iulian Serban","Michael Noseworthy","Prasanna Parthasarathi","Joelle Pineau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188678,"objectID":"ee40ac9e977ce4ed47ecd21d5ff5a0b0","permalink":"https://koustuvsinha.com/publication/gontier-2018/","publishdate":"2022-07-18T23:57:57.929156Z","relpermalink":"/publication/gontier-2018/","section":"publication","summary":"Current conversational systems can follow simple commands and answer basic questions, but they have difficulty maintaining coherent and open-ended conversations about specific topics. Competitions like the Conversational Intelligence (ConvAI) challenge are being organized to push the research development towards that goal. This article presents in detail the RLLChatbot that participated in the 2017 ConvAI challenge. The goal of this research is to better understand how current deep learning and reinforcement learning tools can be used to build a robust yet flexible open domain conversational agent. We provide a thorough description of how a dialog system can be built and trained from mostly public-domain datasets using an ensemble model. The first contribution of this work is a detailed description and analysis of different text generation models in addition to novel message ranking and selection methods. Moreover, a new open-source conversational dataset is presented. Training on this data significantly improves the Recall@k score of the ranking and selection mechanisms compared to our baseline model responsible for selecting the message returned at each interaction. ","tags":[],"title":"The RLLChatbot: a solution to the ConvAI Challenge","type":"publication"},{"authors":null,"categories":null,"content":"\r[11/02/22] Successfully defended my PhD! Checkout my thesis here.\n[08/29/22] Excited to announce a major life event: I’m starting today as a Research Scientist (Speech \u0026amp; NLP) in Meta AI New York!\n[08/19/22] Happy to announce yet another Machine Learning Reproducibility Challenge, the MLRC 2022! This is our six edition!\n[01/10/21] Happy to update that our paper “Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little” is accepted as a long paper at EMNLP 2021!\n[01/09/21] Happy to announce the new iteration of ML Reproducibility Challenge 2021, which has now enlarged to cover 9 top ML conferences! Submit your reports through Feb 2022!\n[03/07/21] On a personal news, got married to my sweetheart Atrayee this July!\n[02/07/21] Thrilled to share that our paper UnNatural Language Inference has received Outstanding Paper Award at ACL 2021! Deeply honored!\n[15/04/21] Announcing the pre-print of our paper “Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little”. We find RoBERTa trained with sentence word order shuffled data performs remarkably close to natural word order pre-trained models on several downstream and probing tasks!\n[01/06/21] Excited to announce that our paper “UnNatural Language Inference”, has been accepted to ACL 2021 (Long paper, Oral), where we stumble upon the weird language understanding mechanisms employed by NLU models!\n[02/10/20] Happy to announce our paper “Measuring Systematic Generalization in Neural Proof Generation with Transformers” is accepted at NeurIPS 2020!\n[05/09/20] Excited to announce the 2020 edition of the ML Reproducibility Challenge! We now cover 7 major ML conferences, do check it out!\n[05/08/20] We released a new blog post on ML Reproducibility Tools and Best Practices. Check it out!\n[30/04/20] Public release of our new multi-task graph dataset, GraphLog. Check out the blog post for more information.\n[08/04/20] Report on NeurIPS 2019 Reproducibility Program published on arxiv. We have also published our thoughts on Designing the Reproducibility Program for NeurIPS 2020 on Medium.\n[15/04/20] Excited to announce two papers accepted to ACL 2020! Probing Linguistic Systematicity and Learning an unreferenced metric for online Dialog evaluation.\n[01/12/19] Co-organizing NeurIPS 2019 ML Retrospectives Workshop\n[01/09/19] Co-organizing NeurIPS 2019 Reproducibility Challenge and honored to be the NeurIPS 2019 Reproducibility Co-Chair.\n[28/01/19] Excited to join Facebook AI Research (FAIR) as PhD Intern!\n[14/08/19] Our paper CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text accepted at EMNLP 2019!\n[28/09/18] Co-organizing ICLR Reproducibility Challenge, 2019\n[04/09/18] Starting PhD at McGill University, advised by Dr Joelle Pineau and Dr William L. Hamilton, from Fall 2018.\n[31/08/18] Our paper on A Hierarchical Neural Attention-based Text Classifier accepted at EMNLP 2018!\n[01/06/18] Intern-ing at Samsung Advanced Institute of Technology for the Summer!\n[01/02/18] Our paper on Ethics in Data Driven Dialog Systems accepted at AAAI/ACM conference on Ethics \u0026amp; Safety.\n","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://koustuvsinha.com/news/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/news/","section":"","summary":"List of news.\r\n","tags":[],"title":"News","type":"page"},{"authors":[],"categories":[],"content":"Koustuv Sinha, Nicolas Angelard-Gontier, Peter Henderson, Prasanna Parthasarathy, Mike Noseworthy \u0026amp; Joelle Pineau\nAs a part of a broader ConvAI challenge, we, the Dialog Group of McGill University under the supervision of Dr Joelle Pineau, have trained a chatbot which can converse fluently with human judges with respect to a given article. The articles are chosen from a broad corpus of SQUAD dataset, where topically they vary from politics to sports to general news. The challenge is to have a fluent conversation with the bot, centering around the topic of the article. Current system uses an ensemble of Generative, Retrieval, and rule based models, and a decision agent learned over actual human-bot responses to select the best candidate response at a given time. We ranked third in the human evaluation round and ranked fourth in the final round held alongside NIPS 2017. Our proposal was also awarded ParlAI research grant from Facebook.\n","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"cf7999a840c22f14652f1ff864d4f242","permalink":"https://koustuvsinha.com/project/rllchatbot/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/project/rllchatbot/","section":"project","summary":"ConvAI 2017 Submission","tags":[],"title":"RLLChatBot","type":"project"},{"authors":[],"categories":[],"content":"Implemented modules:\nDegree Centrality Betweenness Centrality Eigenvalue Centrality Built as a project for Comp 767, Fall 2016, McGill University\n","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"cc05575fef7506f853a99929f28635b1","permalink":"https://koustuvsinha.com/project/networkjs/","publishdate":"2016-11-01T00:00:00Z","relpermalink":"/project/networkjs/","section":"project","summary":"NetworkX clone in JavaScript!","tags":[],"title":"NetworkJS","type":"project"},{"authors":null,"categories":null,"content":" [11/02/22] Successfully defended my PhD! Checkout my thesis here. [08/29/22] Excited to announce a major life event: I’m starting today as a Research Scientist (Speech \u0026amp; NLP) in Meta AI New York! [08/19/22] Happy to announce yet another Machine Learning Reproducibility Challenge, the MLRC 2022! This is our six edition! [01/10/21] Happy to update that our paper “Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little” is accepted as a long paper at EMNLP 2021! [01/09/21] Happy to announce the new iteration of ML Reproducibility Challenge 2021, which has now enlarged to cover 9 top ML conferences! Submit your reports through Feb 2022! [03/07/21] On a personal news, got married to my sweetheart Atrayee this July! [02/07/21] Thrilled to share that our paper UnNatural Language Inference has received Outstanding Paper Award at ACL 2021! Deeply honored! [15/04/21] Announcing the pre-print of our paper “Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little”. We find RoBERTa trained with sentence word order shuffled data performs remarkably close to natural word order pre-trained models on several downstream and probing tasks! [01/06/21] Excited to announce that our paper “UnNatural Language Inference”, has been accepted to ACL 2021 (Long paper, Oral), where we stumble upon the weird language understanding mechanisms employed by NLU models! [02/10/20] Happy to announce our paper “Measuring Systematic Generalization in Neural Proof Generation with Transformers” is accepted at NeurIPS 2020! [05/09/20] Excited to announce the 2020 edition of the ML Reproducibility Challenge! We now cover 7 major ML conferences, do check it out! [05/08/20] We released a new blog post on ML Reproducibility Tools and Best Practices. Check it out! [30/04/20] Public release of our new multi-task graph dataset, GraphLog. Check out the blog post for more information. [08/04/20] Report on NeurIPS 2019 Reproducibility Program published on arxiv. We have also published our thoughts on Designing the Reproducibility Program for NeurIPS 2020 on Medium. [15/04/20] Excited to announce two papers accepted to ACL 2020! Probing Linguistic Systematicity and Learning an unreferenced metric for online Dialog evaluation. [01/12/19] Co-organizing NeurIPS 2019 ML Retrospectives Workshop [01/09/19] Co-organizing NeurIPS 2019 Reproducibility Challenge and honored to be the NeurIPS 2019 Reproducibility Co-Chair. [28/01/19] Excited to join Facebook AI Research (FAIR) as PhD Intern! [14/08/19] Our paper CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text accepted at EMNLP 2019! [28/09/18] Co-organizing ICLR Reproducibility Challenge, 2019 [04/09/18] Starting PhD at McGill University, advised by Dr Joelle Pineau and Dr William L. Hamilton, from Fall 2018. [31/08/18] Our paper on A Hierarchical Neural Attention-based Text Classifier accepted at EMNLP 2018! [01/06/18] Intern-ing at Samsung Advanced Institute of Technology for the Summer! [01/02/18] Our paper on Ethics in Data Driven Dialog Systems accepted at AAAI/ACM conference on Ethics \u0026amp; Safety. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4ba0b231c7eeb0b6fffbbe093c76caa6","permalink":"https://koustuvsinha.com/newslist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/newslist/","section":"","summary":"[11/02/22] Successfully defended my PhD! Checkout my thesis here. [08/29/22] Excited to announce a major life event: I’m starting today as a Research Scientist (Speech \u0026 NLP) in Meta AI New York!","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Mentorship I’m open to mentor early career (MSc/PhD) students to guide them in their own research topics. Please contact me with your CV and brief description of the research problem (no need to write an elaborate plan) you are interested in, and I’ll get back to you. You can check out my publications page to understand my area of expertise, to evaluate where I can guide you the best.\nSupervising Shanya Sharma, 2020-present Manan Dey, 2020-present Tutorials Towards Reproducible Machine Learning Research in Natural Language Processing, ACL 2022 (Website, ACL Anthology) Towards Reproducible Machine Learning Research in Information Retrieval, SIGIR 2022 (Conference Website) Public Talks Panelist, Reproducibility and Rigor in ML, ML Evaluation Standards Workshop at ICLR 2022, April 2022 Evaluating Logical Generalization with Graph Neural Networks, Weights and Biases Salon, (Online) May 2020 ML Reproducibility - From Theory to Practice DL4Science Seminar, Lawrence Berkeley National Laboratory, Berkeley, (Online) August 2020 MICCAI Hackathon, Peru, 2020 (Online), October 2020 Bielefield University, Germany, hosted by Malte Schilling, October 2021 (Online) Conference Organization NeurIPS 2022, Journal Chair NeurIPS 2020, Reproducibility Co-Chair NeurIPS 2019, Reproducibility Co-Chair Workshop Organization [Upcoming] NILLI: Novel Ideas for Learning to Learn with Interaction @ EMNLP 2022 NILLI: Novel Ideas for Learning to Learn with Interaction @ EMNLP 2021 ML Retrospectives@ NeurIPS 2019 Reproducibility Challenge Organization 2021 ML Reproducibility Challenge 2020 ML Reproducibility Challenge 2019 NeurIPS Reproducibility Challenge ICLR 2019 Reproducibility Challenge ICLR 2018 Reproducibility Challenge Conference Volunteering NeurIPS 2018, Montreal, Canada MAIS 2018, Montreal, Canada ICWSM 2017, Montreal, Canada Teaching Assistantship Winter 2022: COMP 424 Artificial Intelligence Fall 2018: COMP 652 Machine Learning Winter 2018: COMP 551 Applied Machine Learning Fall 2017: COMP 551 Applied Machine Learning Winter 2017: COMP 102B Computers and Computing Fall 2016: COMP 189 Computers and Society ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e0bef30d10398c323f9d4183403ccadc","permalink":"https://koustuvsinha.com/activities/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/activities/","section":"","summary":"Mentorship I’m open to mentor early career (MSc/PhD) students to guide them in their own research topics. Please contact me with your CV and brief description of the research problem (no need to write an elaborate plan) you are interested in, and I’ll get back to you.","tags":null,"title":"Activities","type":"page"}]